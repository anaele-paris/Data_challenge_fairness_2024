{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:12:42.414580: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 21:12:42.446719: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 21:12:43.026701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from evaluator_ANAELE import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "# to show performance\n",
    "\n",
    "def evaluate(Y_pred,Y,S,will_print=1):\n",
    "    '''returns model accuracy, final score, macro fscore ans TPR gap\n",
    "    input : 2 np arrays of same dimension\n",
    "    output : array of 4 values\n",
    "    '''\n",
    "    accuracy= accuracy_score(Y, Y_pred)  # Y_test are your original test labels\n",
    "    print(f\"Accuracy on transformed test data: {accuracy}\")\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "    final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "\n",
    "    if will_print==1:\n",
    "        #print results\n",
    "        print('final score',final_score)\n",
    "        print('macro_fscore',eval_scores['macro_fscore'])\n",
    "        print('1-eval_scores[\\'TPR_GAP\\']',1-eval_scores['TPR_GAP'])\n",
    "    \n",
    "    return accuracy, final_score, eval_scores['macro_fscore'],1-eval_scores['TPR_GAP'] , eval_scores , confusion_matrices_eval\n",
    "\n",
    "# to predict X_test and save to file\n",
    "\n",
    "def save_X_test_true(X, model,name):\n",
    "    Y_pred = model.predict(X)\n",
    "    results=pd.DataFrame(y_pred, columns= ['score'])\n",
    "    file_name = \"Data_Challenge_MDI_341_\"+str(name)+\".csv\"\n",
    "    results.to_csv(file_name, header = None, index = None)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'X_test', 'Y', 'S_train', 'S_test'])\n",
      "(27749, 768) (27749,) (27749,) (11893, 768) (11893,)\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# LOAD DATA, \n",
    "#############################################################\n",
    "\n",
    "# Load pickle file and convert to numpy array\n",
    "with open('data-challenge-student.pickle', 'rb') as handle:\n",
    "    # dat = pickle.load(handle)\n",
    "    dat = pd.read_pickle(handle)\n",
    " \n",
    "#Check keys()\n",
    "print(dat.keys())\n",
    "X = dat['X_train']\n",
    "Y = dat['Y']\n",
    "S = dat['S_train']\n",
    "\n",
    "#create a label to distiguish 56 labels Y x 2 (man or woman)\n",
    "# 0 to 27 = non sensitive group | 28 + [0 , 27] = 28 to 55 = sensitive group\n",
    "Y56 = Y+28*S\n",
    "\n",
    "X_test_true = dat['X_test']\n",
    "S_test_true = dat['S_test']\n",
    "\n",
    "# check size\n",
    "print(X.shape,Y.shape,S.shape,X_test_true.shape,S_test_true.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (22199, 768) (22199,) (22199,)\n",
      "test: (5550, 768) (5550,) (5550,)\n",
      "train_tensor: torch.Size([22199, 768]) torch.Size([22199]) torch.Size([22199]) <class 'torch.Tensor'>\n",
      "test_tensor: torch.Size([5550, 768]) torch.Size([5550]) torch.Size([5550]) <class 'torch.Tensor'>\n",
      "Y_train_one_hot: torch.Size([22199, 28]) <class 'torch.Tensor'>\n",
      "X_test_true_tensor: torch.Size([11893, 768]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# train_test_split (np.arrays)\n",
    "##############################################################\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y56_train, Y56_test = train_test_split(X, Y56, test_size=0.2, random_state=42)\n",
    "Y_train = Y56_train % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_train = Y56_train//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "Y_test = Y56_test % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_test = Y56_test//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "\n",
    "# impression des dimensions\n",
    "print('train:',X_train.shape,Y_train.shape,S_train.shape)\n",
    "print('test:',X_test.shape,Y_test.shape, S_test.shape)\n",
    "\n",
    "##############################################################\n",
    "# 1. Transform DataFrames into Tensors\n",
    "##############################################################\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "S_train_tensor = torch.tensor(S_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.long)\n",
    "S_test_tensor = torch.tensor(S_test.values, dtype=torch.long)\n",
    "\n",
    "Y_train_one_hot = torch.nn.functional.one_hot(Y_train_tensor, num_classes=Y_train.nunique())\n",
    "Y_test_one_hot = torch.nn.functional.one_hot(Y_test_tensor, num_classes=Y_train.nunique())\n",
    "\n",
    "X_test_true_tensor = torch.tensor(X_test_true.values, dtype=torch.float32)\n",
    "\n",
    "# impression des dimensions\n",
    "print('train_tensor:',X_train_tensor.shape,Y_train_tensor.shape,S_train_tensor.shape, type(X_train_tensor))\n",
    "print('test_tensor:',X_test_tensor.shape,Y_test_tensor.shape, S_test_tensor.shape, type(X_test_tensor))\n",
    "print('Y_train_one_hot:',Y_train_one_hot.shape, type(Y_train_one_hot))\n",
    "print('X_test_true_tensor:',X_test_true_tensor.shape, type(X_test_true_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#  DEFINE CUSTOM LOSS FUNCTION AND EVALUATION FUNCTIONS\n",
    "#   \n",
    "#   soft_f1_loss\n",
    "#   macro_soft_f1_loss\n",
    "#   calculate_exact_macro_f1\n",
    "#   calculate_class_tpr_gap\n",
    "#   average_tpr_gap_per_class\n",
    "#   \n",
    "##############################################################\n",
    "\n",
    "\n",
    "def soft_f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Differentiable approximation of the F1 score as a loss function.\n",
    "    \"\"\"\n",
    "    y_pred_probs = torch.softmax(y_pred, dim=1)\n",
    "    tp = torch.sum(y_true * y_pred_probs, dim=0)\n",
    "    pp = torch.sum(y_pred_probs, dim=0)\n",
    "    ap = torch.sum(y_true, dim=0)\n",
    "    precision = tp / (pp + 1e-6)\n",
    "    recall = tp / (ap + 1e-6)\n",
    "    soft_f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    loss = 1 - soft_f1.mean()  # Mean to aggregate over all classes\n",
    "    return loss\n",
    "\n",
    "def soft_macro_f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Differentiable approximation of the macro F1 score as a loss function.\n",
    "    Calculates the F1 score for each class independently and then takes the average.\n",
    "    \"\"\"\n",
    "    y_pred_probs = torch.softmax(y_pred, dim=1)\n",
    "    tp = torch.sum(y_true * y_pred_probs, dim=0)\n",
    "    pp = torch.sum(y_pred_probs, dim=0)\n",
    "    ap = torch.sum(y_true, dim=0)\n",
    "    \n",
    "    precision = tp / (pp + 1e-6)\n",
    "    recall = tp / (ap + 1e-6)\n",
    "    \n",
    "    f1_per_class = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    macro_f1 = torch.mean(f1_per_class)  # Average F1 score across all classes\n",
    "    \n",
    "    loss = 1 - macro_f1  # Minimizing loss is maximizing macro F1 score\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_macro_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the exact macro F1 score for evaluation.\n",
    "    Input : any format as tensors will be converted to Tensors of true label if dim >1 . Can be :\n",
    "        - Tensor of probabilities(y_pred_probs) dimension (n,28)\n",
    "        - Tensor of labels, one hote encoded (y_pred_one_hot) dimension (n,28)\n",
    "        - Tensor of labels (y_pred_tensor) dimension (n,1)\n",
    "    Ouput : scalar\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "\n",
    "    \" predict macro f1\"\n",
    "    f1 = f1_score(y_true_labels.cpu().numpy(), y_pred_labels.cpu().numpy(), average='macro')\n",
    "    return f1\n",
    "\n",
    "def get_tpr_gap(y_true, y_pred, protected_attribute, class_idx):\n",
    "    \"\"\"\n",
    "    Calculate the TPR gap for a specific class across protected groups.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred_probs: Tensor of predicted probabilities (after softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    - class_idx: Index of the class for which to calculate the TPR gap.\n",
    "    \n",
    "    Returns:\n",
    "    - TPR gap for the specified class.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "    \n",
    "    # Calculate overall TPR for the current class\n",
    "    overall_mask = y_true_labels == class_idx\n",
    "    overall_tpr = torch.sum((y_pred_labels == class_idx) & overall_mask).float() / (torch.sum(overall_mask).float() + 1e-6)\n",
    "    \n",
    "    # Initialize list to store TPR for each protected group\n",
    "    group_tprs = []\n",
    "    \n",
    "    # Calculate TPR for each protected group\n",
    "    for group_val in protected_attribute.unique():\n",
    "        group_mask = (protected_attribute == group_val) & overall_mask\n",
    "        group_tpr = torch.sum((y_pred_labels == class_idx) & group_mask).float() / (torch.sum(group_mask).float() + 1e-6)\n",
    "        group_tprs.append(group_tpr)\n",
    "    \n",
    "    # Calculate TPR gap for the current class\n",
    "    tpr_gaps = torch.abs(torch.tensor(group_tprs) - overall_tpr)\n",
    "    \n",
    "    return torch.mean(tpr_gaps)  # Return the mean TPR gap for this class\n",
    "\n",
    "def get_macro_tpr_gap(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Calculate the average TPR gap per class by calling tpr_gap for each class.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred: Tensor of predicted logits (before softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    \n",
    "    Returns:\n",
    "    - Average TPR gap across all classes.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "    \n",
    "    # Initialize list to store TPR gaps for all classes\n",
    "    class_tpr_gaps = []\n",
    "    \n",
    "    # Iterate over each class\n",
    "    num_classes = len(y_true_labels.unique())\n",
    "    for class_idx in range(num_classes):\n",
    "        class_tpr_gap = get_tpr_gap(y_true_labels, y_pred_labels, protected_attribute, class_idx)\n",
    "        class_tpr_gaps.append(class_tpr_gap)\n",
    "    \n",
    "    # Calculate the average TPR gap across all classes\n",
    "    avg_tpr_gap = torch.mean(torch.stack(class_tpr_gaps))\n",
    "    \n",
    "    return avg_tpr_gap\n",
    "\n",
    "\n",
    "'''def get_tpr_gap(y_true, y_pred, protected_attribute, class_idx):\n",
    "    \"\"\"\n",
    "    Calculate the TPR gap for a specific class across protected groups.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred_probs: Tensor of predicted probabilities (after softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    - class_idx: Index of the class for which to calculate the TPR gap.\n",
    "    \n",
    "    Returns:\n",
    "    - TPR gap for the specified class.\n",
    "    \"\"\"\n",
    "    # Convert one-hot labels to class indices for gathering\n",
    "    y_true_indices = torch.argmax(y_true, dim=1)\n",
    "    \n",
    "    # Calculate overall TPR for the current class\n",
    "    overall_mask = y_true_indices == class_idx\n",
    "    overall_tpr = torch.sum((y_pred_probs[:, class_idx] > 0.5) & overall_mask).float() / (torch.sum(overall_mask).float() + 1e-6)\n",
    "    \n",
    "    # Initialize list to store TPR for each protected group\n",
    "    group_tprs = []\n",
    "    \n",
    "    # Calculate TPR for each protected group\n",
    "    for group_val in protected_attribute.unique():\n",
    "        group_mask = (protected_attribute == group_val) & overall_mask\n",
    "        group_tpr = torch.sum((y_pred_probs[:, class_idx] > 0.5) & group_mask).float() / (torch.sum(group_mask).float() + 1e-6)\n",
    "        group_tprs.append(group_tpr)\n",
    "    \n",
    "    # Calculate TPR gap for the current class\n",
    "    tpr_gaps = torch.abs(torch.tensor(group_tprs) - overall_tpr)\n",
    "    \n",
    "    return torch.mean(tpr_gaps)  # Return the mean TPR gap for this class\n",
    "'''\n",
    "'''def get_macro_tpr_gap(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Calculate the average TPR gap per class by calling tpr_gap for each class.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred: Tensor of predicted logits (before softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    \n",
    "    Returns:\n",
    "    - Average TPR gap across all classes.\n",
    "    \"\"\"\n",
    "    # Apply softmax to get probabilities\n",
    "    y_pred_probs = torch.softmax(y_pred, dim=1)\n",
    "    \n",
    "    # Initialize list to store TPR gaps for all classes\n",
    "    class_tpr_gaps = []\n",
    "    \n",
    "    # Iterate over each class\n",
    "    num_classes = len(y_true.unique())\n",
    "    for class_idx in range(num_classes):\n",
    "        class_tpr_gap = get_tpr_gap(y_true, y_pred_probs, protected_attribute, class_idx)\n",
    "        class_tpr_gaps.append(class_tpr_gap)\n",
    "    \n",
    "    # Calculate the average TPR gap across all classes\n",
    "    avg_tpr_gap = torch.mean(torch.stack(class_tpr_gaps))\n",
    "    \n",
    "    return avg_tpr_gap\n",
    "'''\n",
    "def soft_final_score_loss(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Combine soft macro F1 score and TPR gap to create a final evaluation metric.\n",
    "    \"\"\"\n",
    "    soft_macro_f1 = soft_macro_f1_loss(y_true, y_pred)  # Calculate soft macro F1 score\n",
    "    macro_tpr_gap = get_macro_tpr_gap(y_true, y_pred, protected_attribute)  # Calculate TPR gap\n",
    "    \n",
    "    soft_final_score = ( soft_macro_f1 + (1 - macro_tpr_gap) ) / 2\n",
    "    return soft_final_score\n",
    "\n",
    "def get_final_score(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Combine soft macro F1 score and TPR gap to create a final evaluation metric.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "\n",
    "    macro_f1 = get_macro_f1(y_true_labels, y_pred_labels)  # Calculate macro F1 score\n",
    "    macro_tpr_gap = get_macro_tpr_gap(y_true_labels, y_pred_labels, protected_attribute)  # Calculate macro TPR gap\n",
    "    \n",
    "    final_score = (macro_f1 + (1 - macro_tpr_gap)) / 2\n",
    "    return final_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NN with customized loss function (soft macro f1 score)**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tensor: torch.Size([22199, 768]) torch.Size([22199]) torch.Size([22199]) <class 'torch.Tensor'>\n",
      "test_tensor: torch.Size([5550, 768]) torch.Size([5550]) torch.Size([5550]) <class 'torch.Tensor'>\n",
      "Y_train_one_hot torch.Size([22199, 28]) <class 'torch.Tensor'>\n",
      "Epoch 1000, Loss: 0.4065406918525696, Final Score Train: 0.6408404111862183, Final Score Test: 0.6703691482543945, macro F1 Train: 0.6432239436677031, macro F1 Test: 0.5888075037853692, 1-TPR Gap Train: 0.9249047040939331, 1-TPR Gap Test: 0.9295457601547241\n",
      "Epoch 2000, Loss: 0.3036802411079407, Final Score Train: 0.6094870567321777, Final Score Test: 0.6459752321243286, macro F1 Train: 0.722747985749416, macro F1 Test: 0.6317000182358751, 1-TPR Gap Train: 0.94172203540802, 1-TPR Gap Test: 0.9236504435539246\n",
      "Epoch 3000, Loss: 0.27086883783340454, Final Score Train: 0.5999405384063721, Final Score Test: 0.6457803249359131, macro F1 Train: 0.7485006381197558, macro F1 Test: 0.6332508399781932, 1-TPR Gap Train: 0.948381781578064, 1-TPR Gap Test: 0.9248114228248596\n",
      "Epoch 4000, Loss: 0.25400209426879883, Final Score Train: 0.5958486795425415, Final Score Test: 0.6455449461936951, macro F1 Train: 0.7605465767648171, macro F1 Test: 0.6371384162661258, 1-TPR Gap Train: 0.9522439241409302, 1-TPR Gap Test: 0.9282283186912537\n",
      "Epoch 5000, Loss: 0.24314600229263306, Final Score Train: 0.592328667640686, Final Score Test: 0.6498181819915771, macro F1 Train: 0.7688522020547771, macro F1 Test: 0.6278699896788557, 1-TPR Gap Train: 0.9535095691680908, 1-TPR Gap Test: 0.9275063276290894\n",
      "Epoch 6000, Loss: 0.23716968297958374, Final Score Train: 0.5902847647666931, Final Score Test: 0.6497665643692017, macro F1 Train: 0.7734044295633474, macro F1 Test: 0.631927726550004, 1-TPR Gap Train: 0.9539739489555359, 1-TPR Gap Test: 0.9314607977867126\n",
      "Epoch 7000, Loss: 0.23217052221298218, Final Score Train: 0.5875598192214966, Final Score Test: 0.6480353474617004, macro F1 Train: 0.7781695085885728, macro F1 Test: 0.6325477780108899, 1-TPR Gap Train: 0.9532890915870667, 1-TPR Gap Test: 0.9286184906959534\n",
      "Epoch 8000, Loss: 0.22510796785354614, Final Score Train: 0.5856208205223083, Final Score Test: 0.6502970457077026, macro F1 Train: 0.7820227511404008, macro F1 Test: 0.6292644541530554, 1-TPR Gap Train: 0.9532644152641296, 1-TPR Gap Test: 0.9298585653305054\n",
      "Epoch 9000, Loss: 0.22249174118041992, Final Score Train: 0.5846235752105713, Final Score Test: 0.6481573581695557, macro F1 Train: 0.7836187630981729, macro F1 Test: 0.6317705567686405, 1-TPR Gap Train: 0.9528659582138062, 1-TPR Gap Test: 0.9280853271484375\n",
      "Epoch 10000, Loss: 0.22058802843093872, Final Score Train: 0.5834739208221436, Final Score Test: 0.6468023061752319, macro F1 Train: 0.7856978899070306, macro F1 Test: 0.6318644632089717, 1-TPR Gap Train: 0.9526457786560059, 1-TPR Gap Test: 0.9254691004753113\n",
      "Epoch 11000, Loss: 0.2178860306739807, Final Score Train: 0.5827494859695435, Final Score Test: 0.6452160477638245, macro F1 Train: 0.7874831181495004, macro F1 Test: 0.6357973054688638, 1-TPR Gap Train: 0.9529820680618286, 1-TPR Gap Test: 0.9262293577194214\n",
      "Epoch 12000, Loss: 0.21605098247528076, Final Score Train: 0.5814636945724487, Final Score Test: 0.6452009677886963, macro F1 Train: 0.78920710689724, macro F1 Test: 0.6339503597852533, 1-TPR Gap Train: 0.9521344900131226, 1-TPR Gap Test: 0.92435222864151\n",
      "Epoch 13000, Loss: 0.21405655145645142, Final Score Train: 0.5815503001213074, Final Score Test: 0.6443980932235718, macro F1 Train: 0.7907806310945044, macro F1 Test: 0.6353849475107367, 1-TPR Gap Train: 0.9538812637329102, 1-TPR Gap Test: 0.9241811037063599\n",
      "Epoch 14000, Loss: 0.21248292922973633, Final Score Train: 0.5811182260513306, Final Score Test: 0.6477892994880676, macro F1 Train: 0.7916738186033221, macro F1 Test: 0.6361303830883018, 1-TPR Gap Train: 0.953910231590271, 1-TPR Gap Test: 0.9317089915275574\n",
      "Epoch 15000, Loss: 0.2110341191291809, Final Score Train: 0.5804467797279358, Final Score Test: 0.6479488015174866, macro F1 Train: 0.7933742622969783, macro F1 Test: 0.635053336994272, 1-TPR Gap Train: 0.9542678594589233, 1-TPR Gap Test: 0.930950939655304\n",
      "Epoch 16000, Loss: 0.2094365358352661, Final Score Train: 0.5800706148147583, Final Score Test: 0.6477702856063843, macro F1 Train: 0.7946161770502588, macro F1 Test: 0.6362843283364942, 1-TPR Gap Train: 0.9547574520111084, 1-TPR Gap Test: 0.9318249225616455\n",
      "Epoch 17000, Loss: 0.20822906494140625, Final Score Train: 0.5796009302139282, Final Score Test: 0.6462807059288025, macro F1 Train: 0.7956260686349542, macro F1 Test: 0.6375239622406902, 1-TPR Gap Train: 0.9548279643058777, 1-TPR Gap Test: 0.9300853610038757\n",
      "Epoch 18000, Loss: 0.20780646800994873, Final Score Train: 0.579254150390625, Final Score Test: 0.6477035284042358, macro F1 Train: 0.796354718279728, macro F1 Test: 0.634101620142448, 1-TPR Gap Train: 0.9548630714416504, 1-TPR Gap Test: 0.9295086860656738\n",
      "Epoch 19000, Loss: 0.2065557837486267, Final Score Train: 0.5787234306335449, Final Score Test: 0.6466960906982422, macro F1 Train: 0.7973487168710219, macro F1 Test: 0.6348033520941446, 1-TPR Gap Train: 0.9547955393791199, 1-TPR Gap Test: 0.9281955361366272\n",
      "Epoch 20000, Loss: 0.20508068799972534, Final Score Train: 0.5781656503677368, Final Score Test: 0.6464270353317261, macro F1 Train: 0.7981488407110268, macro F1 Test: 0.6338793168084645, 1-TPR Gap Train: 0.9544801712036133, 1-TPR Gap Test: 0.9267334342002869\n",
      "Epoch 21000, Loss: 0.20464307069778442, Final Score Train: 0.5779467225074768, Final Score Test: 0.6458468437194824, macro F1 Train: 0.7986114339853637, macro F1 Test: 0.6347578502807271, 1-TPR Gap Train: 0.9545049071311951, 1-TPR Gap Test: 0.9264515042304993\n",
      "Epoch 22000, Loss: 0.20890086889266968, Final Score Train: 0.578286349773407, Final Score Test: 0.6467441916465759, macro F1 Train: 0.7983710878922082, macro F1 Test: 0.63348275843398, 1-TPR Gap Train: 0.9549437761306763, 1-TPR Gap Test: 0.9269711375236511\n",
      "Epoch 23000, Loss: 0.20321333408355713, Final Score Train: 0.5773952007293701, Final Score Test: 0.647848904132843, macro F1 Train: 0.7993456091119114, macro F1 Test: 0.6336661129598707, 1-TPR Gap Train: 0.9541359543800354, 1-TPR Gap Test: 0.9293639063835144\n",
      "Epoch 24000, Loss: 0.2026733160018921, Final Score Train: 0.5772055387496948, Final Score Test: 0.6481566429138184, macro F1 Train: 0.7998379475483369, macro F1 Test: 0.6320450983191314, 1-TPR Gap Train: 0.9542489647865295, 1-TPR Gap Test: 0.9283583760261536\n",
      "Epoch 25000, Loss: 0.2016494870185852, Final Score Train: 0.5763247013092041, Final Score Test: 0.6487993001937866, macro F1 Train: 0.8008320749710979, macro F1 Test: 0.6327253648334042, 1-TPR Gap Train: 0.9534814357757568, 1-TPR Gap Test: 0.9303238987922668\n",
      "Epoch 26000, Loss: 0.20119041204452515, Final Score Train: 0.5762667655944824, Final Score Test: 0.6487483382225037, macro F1 Train: 0.8010357089562868, macro F1 Test: 0.6332011071711274, 1-TPR Gap Train: 0.953569233417511, 1-TPR Gap Test: 0.9306977987289429\n",
      "Epoch 27000, Loss: 0.20077133178710938, Final Score Train: 0.5761929750442505, Final Score Test: 0.64845871925354, macro F1 Train: 0.8014170371477505, macro F1 Test: 0.6341968830489924, 1-TPR Gap Train: 0.9538030028343201, 1-TPR Gap Test: 0.9311143755912781\n",
      "Epoch 28000, Loss: 0.20047348737716675, Final Score Train: 0.5761508941650391, Final Score Test: 0.6483880877494812, macro F1 Train: 0.8014899778971946, macro F1 Test: 0.6337605446052544, 1-TPR Gap Train: 0.9537917375564575, 1-TPR Gap Test: 0.930536687374115\n",
      "Epoch 29000, Loss: 0.2001715898513794, Final Score Train: 0.5759683847427368, Final Score Test: 0.6490667462348938, macro F1 Train: 0.8017285330618801, macro F1 Test: 0.6327665112329585, 1-TPR Gap Train: 0.9536652565002441, 1-TPR Gap Test: 0.930899977684021\n",
      "Epoch 30000, Loss: 0.19966411590576172, Final Score Train: 0.5758355855941772, Final Score Test: 0.6483052372932434, macro F1 Train: 0.8021941296204425, macro F1 Test: 0.6330833983559353, 1-TPR Gap Train: 0.9538653492927551, 1-TPR Gap Test: 0.929693877696991\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m get_macro_f1(Y_test_tensor, Y_pred_tensor)\n\u001b[1;32m     82\u001b[0m inv_macro_tpr_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m get_macro_tpr_gap(Y_test_tensor, Y_pred_probs, S_test_tensor)\n\u001b[0;32m---> 83\u001b[0m final_score \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_score\u001b[49m(Y_test_tensor, Y_pred_probs, S_test_tensor)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal Evaluation Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_score\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Macro F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmacro_f1\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 1-TPR_gap: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39minv_macro_tpr_gap\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_score' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Transform DataFrames into Tensors\n",
    "# ------------------------------------\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "S_train_tensor = torch.tensor(S_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.long)\n",
    "S_test_tensor = torch.tensor(S_test.values, dtype=torch.long)\n",
    "\n",
    "Y_train_one_hot = torch.nn.functional.one_hot(Y_train_tensor, num_classes=Y_train.nunique())\n",
    "Y_test_one_hot = torch.nn.functional.one_hot(Y_test_tensor, num_classes=Y_train.nunique())\n",
    "\n",
    "# impression des dimensions\n",
    "print('train_tensor:',X_train_tensor.shape,Y_train_tensor.shape,S_train_tensor.shape, type(X_train_tensor))\n",
    "print('test_tensor:',X_test_tensor.shape,Y_test_tensor.shape, S_test_tensor.shape, type(X_test_tensor))\n",
    "print('Y_train_one_hot',Y_train_one_hot.shape, type(Y_train_one_hot))\n",
    "      \n",
    "# 2. Define the model and optimizer\n",
    "# ---------------------------------\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(768, 28),  # Assuming 768 input features and 28 classes\n",
    "    nn.ReLU(),  # Adding a ReLU activation function\n",
    "    nn.Linear(28, 28),  # Additional layer for complexity\n",
    "    nn.LogSoftmax(dim=1)  # LogSoftmax for multi-class classification\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# 3. Train the model with the custom loss function final_eval\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "num_epochs = 30000  # Adjust as necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs_train = model(X_train_tensor)\n",
    "    # loss = soft_final_score_loss(Y_train_one_hot.float(), outputs_train, S_train_tensor)\n",
    "    loss = soft_macro_f1_loss(Y_train_one_hot.float(), outputs_train)\n",
    "    # loss = get_macro_tpr_gap(Y_train_one_hot.float(), outputs_train, S_train_tensor )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Calculate metrics for training data\n",
    "            outputs_train = model(X_train_tensor) # probabilities\n",
    "\n",
    "            # Evaluate predictions on training data\n",
    "            final_score_train = get_final_score(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "            macro_f1_train = get_macro_f1(Y_train_tensor, outputs_train)\n",
    "            inv_macro_tpr_gap_train = 1 - get_macro_tpr_gap(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "            \n",
    "            # Calculate metrics for test data\n",
    "            outputs_test = model(X_test_tensor)\n",
    "\n",
    "            # Evaluate predictions on training data\n",
    "            final_score_test = get_final_score(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "            macro_f1_test = get_macro_f1(Y_test_tensor, outputs_test)\n",
    "            inv_macro_tpr_gap_test = 1 - get_macro_tpr_gap(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Final Score Train: {final_score_train.item()}, Final Score Test: {final_score_test.item()}, macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}, 1-TPR Gap Train: {inv_macro_tpr_gap_train}, 1-TPR Gap Test: {inv_macro_tpr_gap_test}')\n",
    "            # print(f'Epoch {epoch + 1}, Loss: {loss.item()},  macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}')# Final Score Train: {final_score_train.item()}, Final Score Test: {final_score_test.item()}, macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}, 1-TPR Gap Train: {inv_macro_tpr_gap_train}, 1-TPR Gap Test: {inv_macro_tpr_gap_test}')\n",
    "\n",
    "\n",
    "# 4. Make Predictions and Evaluate with final_score\n",
    "# -------------------------------------------------\n",
    "            \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    Y_pred_probs = model(X_test_tensor) # dim = 28\n",
    "    Y_pred_tensor = torch.argmax(Y_pred_probs, dim=1)  # dim = 1 (Get the class with the highest probability)\n",
    "    Y_pred_one_hot = torch.nn.functional.one_hot(Y_pred_tensor, num_classes=28)  # dim = 28\n",
    " \n",
    "    macro_f1 = get_macro_f1(Y_test_tensor, Y_pred_tensor)\n",
    "    inv_macro_tpr_gap = 1 - get_macro_tpr_gap(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    final_score = get_final_score(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    print(f'Final Evaluation Score: {final_score.item()} Macro F1: {macro_f1.item()} 1-TPR_gap: { inv_macro_tpr_gap.item() }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation Score: 0.6483052372932434 Macro F1: 0.6330833983559353 1-TPR_gap: 0.929693877696991\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    Y_pred_probs = model(X_test_tensor) # dim = 28\n",
    "    Y_pred_tensor = torch.argmax(Y_pred_probs, dim=1)  # dim = 1 (Get the class with the highest probability)\n",
    "    Y_pred_one_hot = torch.nn.functional.one_hot(Y_pred_tensor, num_classes=28)  # dim = 28\n",
    " \n",
    "    macro_f1 = get_macro_f1(Y_test_tensor, Y_pred_tensor)\n",
    "    inv_macro_tpr_gap = 1 - get_macro_tpr_gap(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    final_score = get_final_score(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    print(f'Final Evaluation Score: {final_score.item()} Macro F1: {macro_f1.item()} 1-TPR_gap: { inv_macro_tpr_gap.item() }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.54      0.66        81\n",
      "           1       0.69      0.63      0.66       127\n",
      "           2       0.79      0.89      0.84       458\n",
      "           3       0.75      0.25      0.38        36\n",
      "           4       0.79      0.69      0.73        48\n",
      "           5       0.82      0.81      0.81        72\n",
      "           6       0.89      0.76      0.82       178\n",
      "           7       0.81      0.70      0.75        54\n",
      "           8       0.82      0.50      0.62        18\n",
      "           9       0.80      0.77      0.78        91\n",
      "          10       0.60      0.41      0.49        22\n",
      "          11       0.66      0.76      0.71       286\n",
      "          12       0.85      0.72      0.78       110\n",
      "          13       0.76      0.77      0.76       258\n",
      "          14       0.82      0.67      0.74       112\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.48      0.42      0.45        33\n",
      "          17       0.71      0.38      0.50        26\n",
      "          18       0.80      0.85      0.82       383\n",
      "          19       0.69      0.83      0.75       611\n",
      "          20       0.65      0.61      0.63        98\n",
      "          21       0.80      0.87      0.83      1636\n",
      "          22       0.67      0.62      0.65       264\n",
      "          23       0.76      0.81      0.79        16\n",
      "          24       0.63      0.52      0.57        89\n",
      "          25       0.00      0.00      0.00       183\n",
      "          26       0.55      0.58      0.56       227\n",
      "          27       0.59      0.71      0.65        14\n",
      "\n",
      "    accuracy                           0.75      5550\n",
      "   macro avg       0.68      0.61      0.63      5550\n",
      "weighted avg       0.73      0.75      0.73      5550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert Y_pred to a DataFrame\n",
    "Y_pred_df = pd.DataFrame(Y_pred_tensor.numpy(), columns=['Predicted'])\n",
    "\n",
    "# Evaluate Y_pred compared to Y_test (assuming Y_test is a numpy array or a pandas Series)\n",
    "print(classification_report(Y_test, Y_pred_df['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_X_test_true\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustom_soft_f1_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36msave_X_test_true\u001b[0;34m(X, model, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_X_test_true\u001b[39m(X, model,name):\n\u001b[0;32m---> 26\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X)\n\u001b[1;32m     27\u001b[0m     results\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Challenge_MDI_341_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(name)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "save_X_test_true(X_test_true, model,'custom_soft_f1_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL CUSTOM LOSS = FINAL SCORE**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tensor: torch.Size([22199, 768]) torch.Size([22199]) torch.Size([22199]) <class 'torch.Tensor'>\n",
      "test_tensor: torch.Size([5550, 768]) torch.Size([5550]) torch.Size([5550]) <class 'torch.Tensor'>\n",
      "Y_train_one_hot torch.Size([22199, 28]) <class 'torch.Tensor'>\n",
      "Epoch 100, Loss: 9.229928970336914, Final Score Train: 0.5473254323005676, Final Score Test: 0.5484995245933533, macro F1 Train: 0.10194340859892699, macro F1 Test: 0.10541046804592533, 1-TPR Gap Train: 0.9927074313163757, 1-TPR Gap Test: 0.9915885925292969\n",
      "Epoch 200, Loss: 8.115486145019531, Final Score Train: 0.6071764826774597, Final Score Test: 0.6037586331367493, macro F1 Train: 0.2593545053976912, macro F1 Test: 0.2511065513502886, 1-TPR Gap Train: 0.9549984335899353, 1-TPR Gap Test: 0.9564107060432434\n",
      "Epoch 300, Loss: 6.555143356323242, Final Score Train: 0.6743472218513489, Final Score Test: 0.6614153981208801, macro F1 Train: 0.4129127061666681, macro F1 Test: 0.39077676498786784, 1-TPR Gap Train: 0.935781717300415, 1-TPR Gap Test: 0.9320540428161621\n",
      "Epoch 400, Loss: 5.279150009155273, Final Score Train: 0.7287893295288086, Final Score Test: 0.7133634090423584, macro F1 Train: 0.5488655092629875, macro F1 Test: 0.5112115882009814, 1-TPR Gap Train: 0.9087131023406982, 1-TPR Gap Test: 0.9155152440071106\n",
      "Epoch 500, Loss: 4.445042133331299, Final Score Train: 0.754325270652771, Final Score Test: 0.7281235456466675, macro F1 Train: 0.6013988275126432, macro F1 Test: 0.5619869681022976, 1-TPR Gap Train: 0.90725177526474, 1-TPR Gap Test: 0.8942601680755615\n",
      "Epoch 600, Loss: 3.746938943862915, Final Score Train: 0.7957514524459839, Final Score Test: 0.7654415965080261, macro F1 Train: 0.6682559775594538, macro F1 Test: 0.6171344528449793, 1-TPR Gap Train: 0.9232468605041504, 1-TPR Gap Test: 0.9137487411499023\n",
      "Epoch 700, Loss: 3.5552239418029785, Final Score Train: 0.8060061931610107, Final Score Test: 0.7674438953399658, macro F1 Train: 0.6814613406812237, macro F1 Test: 0.6184053355328469, 1-TPR Gap Train: 0.9305511116981506, 1-TPR Gap Test: 0.9164824485778809\n",
      "Epoch 800, Loss: 3.390350580215454, Final Score Train: 0.8155328035354614, Final Score Test: 0.7652165293693542, macro F1 Train: 0.6940205601553497, macro F1 Test: 0.6324574460810327, 1-TPR Gap Train: 0.9370449781417847, 1-TPR Gap Test: 0.8979756236076355\n",
      "Epoch 900, Loss: 3.243572473526001, Final Score Train: 0.8253369331359863, Final Score Test: 0.7811043858528137, macro F1 Train: 0.7063193996449474, macro F1 Test: 0.6452946454296967, 1-TPR Gap Train: 0.9443544149398804, 1-TPR Gap Test: 0.9169141054153442\n",
      "Epoch 1000, Loss: 3.1158578395843506, Final Score Train: 0.8282827138900757, Final Score Test: 0.7871873378753662, macro F1 Train: 0.7130116338752722, macro F1 Test: 0.6532851423870488, 1-TPR Gap Train: 0.9435538053512573, 1-TPR Gap Test: 0.9210895299911499\n",
      "Final Evaluation Score: 0.7871873378753662 Macro F1: 0.6532851423870488 1-TPR_gap: 0.9210895299911499\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# 2. Define the model and optimizer\n",
    "# ---------------------------------\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(768, 28),  # Assuming 768 input features and 28 classes\n",
    "    nn.ReLU(),  # Adding a ReLU activation function\n",
    "    nn.Linear(28, 28),  # Additional layer for complexity\n",
    "    nn.LogSoftmax(dim=1)  # LogSoftmax for multi-class classification\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 3. Train the model with the custom loss function final_eval\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "num_epochs = 1000  # Adjust as necessary\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs_train = model(X_train_tensor)\n",
    "    \n",
    "    #loss = soft_final_score_loss(Y_train_one_hot.float(), outputs_train, S_train_tensor)\n",
    "    loss = soft_macro_f1_loss(Y_train_one_hot.float(), outputs_train)*10 + get_macro_tpr_gap(Y_train_one_hot.float(), outputs_train, S_train_tensor )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Calculate metrics for training data\n",
    "            outputs_train = model(X_train_tensor) # probabilities\n",
    "\n",
    "            # Evaluate predictions on training data\n",
    "            final_score_train = get_final_score(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "            macro_f1_train = get_macro_f1(Y_train_tensor, outputs_train)\n",
    "            inv_macro_tpr_gap_train = 1 - get_macro_tpr_gap(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "            \n",
    "            # Calculate metrics for test data\n",
    "            outputs_test = model(X_test_tensor)\n",
    "\n",
    "            # Evaluate predictions on training data\n",
    "            final_score_test = get_final_score(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "            macro_f1_test = get_macro_f1(Y_test_tensor, outputs_test)\n",
    "            inv_macro_tpr_gap_test = 1 - get_macro_tpr_gap(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Final Score Train: {final_score_train.item()}, Final Score Test: {final_score_test.item()}, macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}, 1-TPR Gap Train: {inv_macro_tpr_gap_train}, 1-TPR Gap Test: {inv_macro_tpr_gap_test}')\n",
    "            # print(f'Epoch {epoch + 1}, Loss: {loss.item()},  macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}')# Final Score Train: {final_score_train.item()}, Final Score Test: {final_score_test.item()}, macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}, 1-TPR Gap Train: {inv_macro_tpr_gap_train}, 1-TPR Gap Test: {inv_macro_tpr_gap_test}')\n",
    "\n",
    "\n",
    "# 4. Make Predictions and Evaluate with final_score\n",
    "# -------------------------------------------------\n",
    "            \n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    Y_pred_probs = model(X_test_tensor) # dim = 28\n",
    "    Y_pred_tensor = torch.argmax(Y_pred_probs, dim=1)  # dim = 1 (Get the class with the highest probability)\n",
    "    Y_pred_one_hot = torch.nn.functional.one_hot(Y_pred_tensor, num_classes=28)  # dim = 28\n",
    " \n",
    "    macro_f1 = get_macro_f1(Y_test_tensor, Y_pred_tensor)\n",
    "    inv_macro_tpr_gap = 1 - get_macro_tpr_gap(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    final_score = get_final_score(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "    print(f'Final Evaluation Score: {final_score.item()} Macro F1: {macro_f1.item()} 1-TPR_gap: { inv_macro_tpr_gap.item() }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64        81\n",
      "           1       0.70      0.57      0.63       127\n",
      "           2       0.81      0.87      0.84       458\n",
      "           3       0.00      0.00      0.00        36\n",
      "           4       0.89      0.65      0.75        48\n",
      "           5       0.81      0.78      0.79        72\n",
      "           6       0.84      0.71      0.77       178\n",
      "           7       0.75      0.74      0.75        54\n",
      "           8       0.92      0.67      0.77        18\n",
      "           9       0.79      0.81      0.80        91\n",
      "          10       0.77      0.45      0.57        22\n",
      "          11       0.55      0.83      0.66       286\n",
      "          12       0.86      0.70      0.77       110\n",
      "          13       0.74      0.73      0.73       258\n",
      "          14       0.86      0.70      0.77       112\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.48      0.48      0.48        33\n",
      "          17       0.74      0.54      0.62        26\n",
      "          18       0.80      0.87      0.84       383\n",
      "          19       0.74      0.81      0.77       611\n",
      "          20       0.59      0.70      0.64        98\n",
      "          21       0.88      0.78      0.83      1636\n",
      "          22       0.51      0.69      0.59       264\n",
      "          23       0.70      0.88      0.78        16\n",
      "          24       0.54      0.66      0.60        89\n",
      "          25       0.64      0.50      0.56       183\n",
      "          26       0.58      0.54      0.56       227\n",
      "          27       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.75      5550\n",
      "   macro avg       0.67      0.65      0.65      5550\n",
      "weighted avg       0.75      0.75      0.75      5550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert Y_pred to a DataFrame\n",
    "Y_pred_df = pd.DataFrame(Y_pred_tensor.numpy(), columns=['Predicted'])\n",
    "\n",
    "# Evaluate Y_pred compared to Y_test (assuming Y_test is a numpy array or a pandas Series)\n",
    "print(classification_report(Y_test, Y_pred_df['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_probs = model(X_test_true_tensor)\n",
    "Y_pred_tensor = torch.argmax(Y_pred_probs, dim=1)\n",
    "\n",
    "results=pd.DataFrame(Y_pred_tensor, columns= ['score'])\n",
    "name = 'NN_with_custom_loss'\n",
    "file_name = \"Data_Challenge_MDI_341_\"+str(name)+\".csv\"\n",
    "results.to_csv(file_name, header = None, index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. REGRESSION WITH CUSTOM LOSS macro F1**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming model, optimizer, X_train_tensor, Y_train_one_hot, X_test_tensor, Y_test are already defined\n",
    "\n",
    "# Convert Y_test to one-hot encoding if it's not already one-hot encoded\n",
    "# This is necessary for consistency in our loss function calculations\n",
    "Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.int64) if isinstance(Y_test, pd.Series) else torch.from_numpy(Y_test).long()\n",
    "Y_test_one_hot = torch.nn.functional.one_hot(Y_test_tensor, num_classes=28)\n",
    "\n",
    "\n",
    "# Define the model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(768, 28),  # Assuming 768 input features and 28 classes\n",
    "    nn.ReLU(),  # Adding a ReLU activation function\n",
    "    nn.Linear(28, 28),  # Additional layer for complexity\n",
    "    nn.LogSoftmax(dim=1)  # LogSoftmax for multi-class classification\n",
    ")\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 10000  # Example number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    \n",
    "    # Forward pass on the training data\n",
    "    outputs_train = model(X_train_tensor)\n",
    "    loss_train = macro_soft_f1_loss(Y_train_one_hot.float(), outputs_train)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # No gradient computation needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        \n",
    "        # Forward pass on the validation data\n",
    "        outputs_test = model(X_test_tensor)\n",
    "        \n",
    "        # Calculate the exact macro F1 score for both training and validation data\n",
    "        f1_train = calculate_exact_macro_f1(Y_train_one_hot.float(), outputs_train)\n",
    "        f1_test = calculate_exact_macro_f1(Y_test_one_hot.float(), outputs_test)\n",
    "        \n",
    "        model.train()  # Set the model back to training mode\n",
    "    \n",
    "    # Print loss and F1 score\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_train.item():.4f}, macro F1 Train: {f1_train:.4f}, macro F1 Test: {f1_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "\n",
    "# Assuming model is already trained and X_test is a DataFrame\n",
    "\n",
    "# Convert X_test to a PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():  # We do not need gradient computation for prediction\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    Y_pred_probs = model(X_test_tensor)\n",
    "    Y_pred = torch.argmax(Y_pred_probs, dim=1)  # Get the class with the highest probability\n",
    "\n",
    "# Convert Y_pred to a DataFrame\n",
    "Y_pred_df = pd.DataFrame(Y_pred.numpy(), columns=['Predicted'])\n",
    "\n",
    "# Evaluate Y_pred compared to Y_test (assuming Y_test is a numpy array or a pandas Series)\n",
    "print(classification_report(Y_test, Y_pred_df['Predicted']))\n",
    "\n",
    "# If you want to use the exact F1 score for evaluation, you can directly use it from sklearn.metrics\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"Exact F1 Score (micro):\", f1_score(Y_test, Y_pred_df['Predicted'],average = 'micro'))  # 'weighted' for multi-class\n",
    "print(\"Exact F1 Score (macro):\", f1_score(Y_test, Y_pred_df['Predicted'], average='macro'))  # 'weighted' for multi-class\n",
    "\n",
    "# Returning Y_pred as a DataFrame makes sense for further analysis or submission\n",
    "#return Y_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CUSTON LOSS FUNCTION TRP GAP**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def gap_TPR(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Calculate the average TPR gap for each class across protected groups.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred: Tensor of predicted logits (before softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    \n",
    "    Returns:\n",
    "    - Average TPR gap across all classes.\n",
    "    \"\"\"\n",
    "    # Apply softmax to get probabilities\n",
    "    y_pred_probs = torch.softmax(y_pred, dim=1)\n",
    "    \n",
    "    # Convert one-hot labels to class indices for gathering\n",
    "    y_true_indices = torch.argmax(y_true, dim=1)\n",
    "    \n",
    "    # Initialize TPR storage\n",
    "    tpr_gaps = []\n",
    "    \n",
    "    # Iterate over each class\n",
    "    num_classes = y_true.shape[1]\n",
    "    for class_idx in range(num_classes):\n",
    "        # Calculate TPR for the current class across all groups\n",
    "        tpr_list = []\n",
    "        \n",
    "        # Calculate overall TPR for the current class\n",
    "        overall_mask = y_true_indices == class_idx\n",
    "        overall_tpr = torch.sum((y_pred_probs[:, class_idx] > 0.5) & overall_mask).float() / torch.sum(overall_mask).float()\n",
    "        \n",
    "        # Calculate TPR for each protected group\n",
    "        for group_val in protected_attribute.unique():\n",
    "            group_mask = (protected_attribute == group_val) & overall_mask\n",
    "            group_tpr = torch.sum((y_pred_probs[:, class_idx] > 0.5) & group_mask).float() / torch.sum(group_mask).float()\n",
    "            tpr_list.append(group_tpr)\n",
    "        \n",
    "        # Calculate TPR gap for the current class and store it\n",
    "        tpr_gaps.append(torch.abs(torch.tensor(tpr_list) - overall_tpr))\n",
    "    \n",
    "    # Calculate the average TPR gap across all classes\n",
    "    avg_tpr_gap = torch.mean(torch.stack(tpr_gaps))\n",
    "    \n",
    "    return avg_tpr_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> (5550,)\n",
      "<class 'torch.Tensor'> torch.Size([5550, 28])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(Y_test),Y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(Y_pred_probs),Y_pred_probs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_macro_tpr_gap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_pred_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mS_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 112\u001b[0m, in \u001b[0;36mget_macro_tpr_gap\u001b[0;34m(y_true, y_pred, protected_attribute)\u001b[0m\n\u001b[1;32m    110\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes):\n\u001b[0;32m--> 112\u001b[0m     class_tpr_gap \u001b[38;5;241m=\u001b[39m \u001b[43mget_tpr_gap\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotected_attribute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     class_tpr_gaps\u001b[38;5;241m.\u001b[39mappend(class_tpr_gap)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Calculate the average TPR gap across all classes\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mget_tpr_gap\u001b[0;34m(y_true, y_pred_probs, protected_attribute, class_idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mCalculate the TPR gap for a specific class across protected groups.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m- TPR gap for the specified class.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Convert one-hot labels to class indices for gathering\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m y_true_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Calculate overall TPR for the current class\u001b[39;00m\n\u001b[1;32m     74\u001b[0m overall_mask \u001b[38;5;241m=\u001b[39m y_true_indices \u001b[38;5;241m==\u001b[39m class_idx\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not Series"
     ]
    }
   ],
   "source": [
    "print(type(Y_test),Y_test.shape)\n",
    "print(type(Y_pred_probs),Y_pred_probs.shape)\n",
    "get_macro_tpr_gap(Y_test,Y_pred_probs,S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
