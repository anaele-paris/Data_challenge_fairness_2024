{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is NOT available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\nfrom tensorflow.keras.layers import Input, Dense, Dropout\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.metrics import AUC, SparseCategoricalAccuracy\\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    " # Example classifier\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from evaluator import *\n",
    "\n",
    "'''import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'X_test', 'Y', 'S_train', 'S_test'])\n",
      "(27749, 768) (27749,) (27749,) (11893, 768) (11893,)\n"
     ]
    }
   ],
   "source": [
    "# Load pickle file and convert to numpy array\n",
    "with open('data-challenge-student.pickle', 'rb') as handle:\n",
    "    # dat = pickle.load(handle)\n",
    "    dat = pd.read_pickle(handle)\n",
    " \n",
    "#Check keys()\n",
    "print(dat.keys())\n",
    "X = dat['X_train']\n",
    "Y = dat['Y']\n",
    "S = dat['S_train']\n",
    "\n",
    "X_test_true = dat['X_test']\n",
    "S_test_true = dat['S_test']\n",
    "\n",
    "print(X.shape,Y.shape,S.shape,X_test_true.shape,S_test_true.shape)\n",
    "\n",
    "# Normalize data (L2 norm recommended for embeddings)\n",
    "#X = normalize(X, norm='l2')\n",
    "#X_test_true = normalize(X_test_true, norm='l2')\n",
    "\n",
    "# Split the data (final _ to keep split data untouched and be able to reload in file)\n",
    "# X_train_, X_test_, Y_train_, Y_test_, S_train_, S_test_ = train_test_split(X, Y, S, test_size=0.3, random_state=42)\n",
    "\n",
    "# Refresh training data\n",
    "# X_train, X_test, Y_train, Y_test, S_train, S_test = X_train_, X_test_, Y_train_, Y_test_, S_train_, S_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (19424, 769) (19424,) (19424,)\n",
      "test (8325, 769) (8325,) (8325,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102235/2873319695.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  XS_train = X_train[S == True]\n",
      "/tmp/ipykernel_102235/2873319695.py:19: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  XnotS_train = X_train[S == False]\n",
      "/tmp/ipykernel_102235/2873319695.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  XS_test = X_test[S == True]\n",
      "/tmp/ipykernel_102235/2873319695.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  XnotS_test = X_test[S == False ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>-0.352127</td>\n",
       "      <td>-0.011900</td>\n",
       "      <td>0.464177</td>\n",
       "      <td>-0.429489</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>-0.355041</td>\n",
       "      <td>0.404765</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>-0.171173</td>\n",
       "      <td>-0.386853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659120</td>\n",
       "      <td>-0.018598</td>\n",
       "      <td>-0.461626</td>\n",
       "      <td>0.263559</td>\n",
       "      <td>0.106523</td>\n",
       "      <td>-0.426319</td>\n",
       "      <td>-0.123851</td>\n",
       "      <td>0.176851</td>\n",
       "      <td>0.700239</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18293</th>\n",
       "      <td>-0.035066</td>\n",
       "      <td>-0.298860</td>\n",
       "      <td>-0.479104</td>\n",
       "      <td>-0.626332</td>\n",
       "      <td>-0.019420</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>-0.043124</td>\n",
       "      <td>-0.156429</td>\n",
       "      <td>-0.086376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595587</td>\n",
       "      <td>-0.015968</td>\n",
       "      <td>-0.765048</td>\n",
       "      <td>0.323093</td>\n",
       "      <td>0.170880</td>\n",
       "      <td>-0.186892</td>\n",
       "      <td>0.661593</td>\n",
       "      <td>0.406664</td>\n",
       "      <td>0.397004</td>\n",
       "      <td>18293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>0.059748</td>\n",
       "      <td>-0.641063</td>\n",
       "      <td>-0.144781</td>\n",
       "      <td>0.100073</td>\n",
       "      <td>0.337262</td>\n",
       "      <td>-0.558625</td>\n",
       "      <td>0.539921</td>\n",
       "      <td>0.473667</td>\n",
       "      <td>-0.363462</td>\n",
       "      <td>-0.405527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235132</td>\n",
       "      <td>-0.101076</td>\n",
       "      <td>-0.915928</td>\n",
       "      <td>0.364703</td>\n",
       "      <td>0.321795</td>\n",
       "      <td>-0.059579</td>\n",
       "      <td>-0.066653</td>\n",
       "      <td>0.360908</td>\n",
       "      <td>0.337702</td>\n",
       "      <td>15870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>-0.424646</td>\n",
       "      <td>-0.094270</td>\n",
       "      <td>-0.975104</td>\n",
       "      <td>-0.402996</td>\n",
       "      <td>-0.248395</td>\n",
       "      <td>0.203762</td>\n",
       "      <td>0.170925</td>\n",
       "      <td>0.119010</td>\n",
       "      <td>-0.242348</td>\n",
       "      <td>-0.148573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755281</td>\n",
       "      <td>-0.236163</td>\n",
       "      <td>-0.255455</td>\n",
       "      <td>-0.083623</td>\n",
       "      <td>-0.183295</td>\n",
       "      <td>-0.180494</td>\n",
       "      <td>0.264272</td>\n",
       "      <td>0.158392</td>\n",
       "      <td>0.278496</td>\n",
       "      <td>6207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25494</th>\n",
       "      <td>-0.144659</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-0.872632</td>\n",
       "      <td>-0.925582</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.324370</td>\n",
       "      <td>-0.124459</td>\n",
       "      <td>0.284658</td>\n",
       "      <td>-0.412551</td>\n",
       "      <td>0.303603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136539</td>\n",
       "      <td>-0.418398</td>\n",
       "      <td>-1.001702</td>\n",
       "      <td>-0.187408</td>\n",
       "      <td>-0.229588</td>\n",
       "      <td>-0.343264</td>\n",
       "      <td>0.321463</td>\n",
       "      <td>0.196229</td>\n",
       "      <td>0.627135</td>\n",
       "      <td>25494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "4002  -0.352127 -0.011900  0.464177 -0.429489  0.022461 -0.355041  0.404765   \n",
       "18293 -0.035066 -0.298860 -0.479104 -0.626332 -0.019420  0.021350  0.052250   \n",
       "15870  0.059748 -0.641063 -0.144781  0.100073  0.337262 -0.558625  0.539921   \n",
       "6207  -0.424646 -0.094270 -0.975104 -0.402996 -0.248395  0.203762  0.170925   \n",
       "25494 -0.144659 -0.019726 -0.872632 -0.925582  0.001781  0.324370 -0.124459   \n",
       "\n",
       "              7         8         9  ...       759       760       761  \\\n",
       "4002   0.256324 -0.171173 -0.386853  ... -0.659120 -0.018598 -0.461626   \n",
       "18293 -0.043124 -0.156429 -0.086376  ... -0.595587 -0.015968 -0.765048   \n",
       "15870  0.473667 -0.363462 -0.405527  ... -0.235132 -0.101076 -0.915928   \n",
       "6207   0.119010 -0.242348 -0.148573  ... -0.755281 -0.236163 -0.255455   \n",
       "25494  0.284658 -0.412551  0.303603  ...  0.136539 -0.418398 -1.001702   \n",
       "\n",
       "            762       763       764       765       766       767  \\\n",
       "4002   0.263559  0.106523 -0.426319 -0.123851  0.176851  0.700239   \n",
       "18293  0.323093  0.170880 -0.186892  0.661593  0.406664  0.397004   \n",
       "15870  0.364703  0.321795 -0.059579 -0.066653  0.360908  0.337702   \n",
       "6207  -0.083623 -0.183295 -0.180494  0.264272  0.158392  0.278496   \n",
       "25494 -0.187408 -0.229588 -0.343264  0.321463  0.196229  0.627135   \n",
       "\n",
       "       original_index  \n",
       "4002             4002  \n",
       "18293           18293  \n",
       "15870           15870  \n",
       "6207             6207  \n",
       "25494           25494  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the original index for later use\n",
    "X['original_index'] = X.index\n",
    "\n",
    "# Step 1: Keep original index by resetting it if not already in a suitable format\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "Y = Y.reset_index(drop=True)\n",
    "S = S.reset_index(drop=True)\n",
    "\n",
    "# Create a combined Y and S DataFrame for stratification\n",
    "YS = pd.DataFrame({'Y': Y, 'S': S})\n",
    "\n",
    "# Split the data while stratifying based on Y and S\n",
    "X_train, X_test, Y_train, Y_test, S_train, S_test = train_test_split(X, Y, S, test_size=0.3, random_state=0, stratify=YS)\n",
    "print('train',X_train.shape,Y_train.shape,S_train.shape)\n",
    "print('test',X_test.shape,Y_test.shape,S_test.shape)\n",
    "\n",
    "# Create XS and XnotS subsets for training and test sets\n",
    "XS_train = X_train[S == True]\n",
    "YS_train = Y_train[S == True]\n",
    "\n",
    "XnotS_train = X_train[S == False]\n",
    "YnotS_train = Y_train[S == False]\n",
    "\n",
    "XS_test = X_test[S == True]\n",
    "YS_test = Y_test[S == True]\n",
    "\n",
    "XnotS_test = X_test[S == False ]\n",
    "XnotS_test = X_test[S == False ]\n",
    "\n",
    "XS_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8953,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4002     13\n",
       "18293    19\n",
       "15870    24\n",
       "6207     21\n",
       "25494    18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_train[S == True].shape)\n",
    "Y_train[S == True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_XnotS \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the models\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model_XS\u001b[38;5;241m.\u001b[39mfit(XS_train, Y_train[S\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      9\u001b[0m model_XnotS\u001b[38;5;241m.\u001b[39mfit(XnotS_train, Y_train[S\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/base.py:441\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[0;32m--> 441\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:2020\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m-> 2020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2021\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m     )\n\u001b[1;32m   2029\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "# Prepare Logistic Regression models\n",
    "model_X = LogisticRegression(random_state=0, max_iter=5000)\n",
    "model_XS = LogisticRegression(random_state=0, max_iter=5000)\n",
    "model_XnotS = LogisticRegression(random_state=0, max_iter=5000)\n",
    "\n",
    "# Train the models\n",
    "model_X.fit(X_train, Y_train)\n",
    "model_XS.fit(XS_train, Y_train[S==1])\n",
    "model_XnotS.fit(XnotS_train, Y_train[S==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predictions on test and train data\n",
    "Y_pred = model_X.predict(X_test.drop(columns=['S', 'original_index']))\n",
    "YS_pred = model_XS.predict(XS_test.drop(columns=['S', 'original_index']))\n",
    "YnotS_pred = model_XnotS.predict(XnotS_test.drop(columns=['S', 'original_index']))\n",
    "\n",
    "Y_pred_train = model_X.predict(X_train.drop(columns=['S', 'original_index']))\n",
    "YS_pred_train = model_XS.predict(XS_train.drop(columns=['S', 'original_index']))\n",
    "YnotS_pred_train = model_XnotS.predict(XnotS_train.drop(columns=['S', 'original_index']))\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_score_X_test = f1_score(Y_test, Y_pred, average='macro')\n",
    "f1_score_XS_test = f1_score(Y_test[XS_test.index], YS_pred, average='macro')\n",
    "f1_score_XnotS_test = f1_score(Y_test[XnotS_test.index], YnotS_pred, average='macro')\n",
    "\n",
    "f1_score_X_train = f1_score(Y_train, Y_pred_train, average='macro')\n",
    "f1_score_XS_train = f1_score(Y_train[XS_train.index], YS_pred_train, average='macro')\n",
    "f1_score_XnotS_train = f1_score(Y_train[XnotS_train.index], YnotS_pred_train, average='macro')\n",
    "\n",
    "# Output F1 scores\n",
    "print(\"F1 Scores for Test Data:\")\n",
    "print(f\"All Data: {f1_score_X_test}, S Data: {f1_score_XS_test}, Not S Data: {f1_score_XnotS_test}\")\n",
    "print(\"F1 Scores for Train Data:\")\n",
    "print(f\"All Data: {f1_score_X_train}, S Data: {f1_score_XS_train}, Not S Data: {f1_score_XnotS_train}\")\n",
    "\n",
    "# Reconstructing the final DataFrame with predictions\n",
    "# Note: For the final_predictions DataFrame, additional manipulation is needed.\n",
    "# Since the structure and desired output were not fully specified in the requirements, below is a conceptual approach.\n",
    "\n",
    "# Merge predictions back based on original indices to maintain order\n",
    "# This step is conceptual and may require adjustments based on actual DataFrame structures and desired output format.\n",
    "test_predictions = pd.DataFrame({\n",
    "    'Y_test': Y_test,\n",
    "    'S_test': S_test,\n",
    "    'Y_pred': Y_pred,\n",
    "    'Y_pred_train': np.nan,  # Placeholder, actual matching by index needed\n",
    "    'YS_pred': np.nan,  # Placeholder for XS_test predictions, actual matching by index needed\n",
    "    'YnotS_pred': np.nan,  # Placeholder for XnotS_test predictions, actual matching by index needed\n",
    "    'YS_pred_train': np.nan,  # Placeholder, actual matching by index needed\n",
    "    'YnotS_pred_train': np.nan  # Placeholder, actual matching by index needed\n",
    "}, index=indices_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12793, 768) (14956, 768)\n",
      "(12793,) (14956,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>0.056359</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>-0.726052</td>\n",
       "      <td>-0.616777</td>\n",
       "      <td>0.064091</td>\n",
       "      <td>-0.068786</td>\n",
       "      <td>0.384864</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>-0.285173</td>\n",
       "      <td>-0.430806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049452</td>\n",
       "      <td>-0.587354</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>-0.402672</td>\n",
       "      <td>0.170605</td>\n",
       "      <td>-0.074348</td>\n",
       "      <td>0.130570</td>\n",
       "      <td>0.328335</td>\n",
       "      <td>0.139750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12083</th>\n",
       "      <td>-0.565799</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.185003</td>\n",
       "      <td>-0.692792</td>\n",
       "      <td>-0.056820</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.241766</td>\n",
       "      <td>-0.113560</td>\n",
       "      <td>-0.138898</td>\n",
       "      <td>-0.768206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071413</td>\n",
       "      <td>-0.310701</td>\n",
       "      <td>0.157026</td>\n",
       "      <td>-0.691291</td>\n",
       "      <td>-0.273562</td>\n",
       "      <td>0.121746</td>\n",
       "      <td>-0.394475</td>\n",
       "      <td>-0.463161</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.264848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12702</th>\n",
       "      <td>-0.684493</td>\n",
       "      <td>-0.188508</td>\n",
       "      <td>-0.670183</td>\n",
       "      <td>-0.572966</td>\n",
       "      <td>-0.117222</td>\n",
       "      <td>0.200948</td>\n",
       "      <td>0.304471</td>\n",
       "      <td>0.259940</td>\n",
       "      <td>-0.248586</td>\n",
       "      <td>-0.271820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236687</td>\n",
       "      <td>-0.772385</td>\n",
       "      <td>-0.041944</td>\n",
       "      <td>-0.674941</td>\n",
       "      <td>0.239194</td>\n",
       "      <td>0.054098</td>\n",
       "      <td>-0.203181</td>\n",
       "      <td>0.663840</td>\n",
       "      <td>0.376015</td>\n",
       "      <td>0.500834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17728</th>\n",
       "      <td>-0.442187</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.321693</td>\n",
       "      <td>-0.552460</td>\n",
       "      <td>-0.083063</td>\n",
       "      <td>-0.383489</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.199604</td>\n",
       "      <td>-0.227831</td>\n",
       "      <td>-0.330898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>-0.598164</td>\n",
       "      <td>-0.170784</td>\n",
       "      <td>-0.412672</td>\n",
       "      <td>0.253084</td>\n",
       "      <td>0.072861</td>\n",
       "      <td>-0.407497</td>\n",
       "      <td>-0.076331</td>\n",
       "      <td>0.210154</td>\n",
       "      <td>0.622336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15415</th>\n",
       "      <td>0.467783</td>\n",
       "      <td>-0.013451</td>\n",
       "      <td>-0.532544</td>\n",
       "      <td>-0.704010</td>\n",
       "      <td>-0.145949</td>\n",
       "      <td>-0.195713</td>\n",
       "      <td>0.415697</td>\n",
       "      <td>-0.249390</td>\n",
       "      <td>-0.451609</td>\n",
       "      <td>0.296516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046805</td>\n",
       "      <td>-0.262006</td>\n",
       "      <td>0.052341</td>\n",
       "      <td>-1.049271</td>\n",
       "      <td>-0.142108</td>\n",
       "      <td>-0.244743</td>\n",
       "      <td>-0.421750</td>\n",
       "      <td>0.151491</td>\n",
       "      <td>0.070547</td>\n",
       "      <td>0.399572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "6286   0.056359  0.003188 -0.726052 -0.616777  0.064091 -0.068786  0.384864   \n",
       "12083 -0.565799  0.118481  0.185003 -0.692792 -0.056820  0.039130  0.241766   \n",
       "12702 -0.684493 -0.188508 -0.670183 -0.572966 -0.117222  0.200948  0.304471   \n",
       "17728 -0.442187 -0.120117  0.321693 -0.552460 -0.083063 -0.383489  0.259511   \n",
       "15415  0.467783 -0.013451 -0.532544 -0.704010 -0.145949 -0.195713  0.415697   \n",
       "\n",
       "            7         8         9    ...       758       759       760  \\\n",
       "6286   0.363644 -0.285173 -0.430806  ... -0.049452 -0.587354 -0.004443   \n",
       "12083 -0.113560 -0.138898 -0.768206  ... -0.071413 -0.310701  0.157026   \n",
       "12702  0.259940 -0.248586 -0.271820  ... -0.236687 -0.772385 -0.041944   \n",
       "17728  0.199604 -0.227831 -0.330898  ...  0.101770 -0.598164 -0.170784   \n",
       "15415 -0.249390 -0.451609  0.296516  ... -0.046805 -0.262006  0.052341   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "6286  -0.924459 -0.402672  0.170605 -0.074348  0.130570  0.328335  0.139750  \n",
       "12083 -0.691291 -0.273562  0.121746 -0.394475 -0.463161  0.132829  0.264848  \n",
       "12702 -0.674941  0.239194  0.054098 -0.203181  0.663840  0.376015  0.500834  \n",
       "17728 -0.412672  0.253084  0.072861 -0.407497 -0.076331  0.210154  0.622336  \n",
       "15415 -1.049271 -0.142108 -0.244743 -0.421750  0.151491  0.070547  0.399572  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XF=X[S==1]\n",
    "XH=X[S==0]\n",
    "print(XF.shape,XH.shape)\n",
    "\n",
    "YF=Y[S==1]\n",
    "YH=Y[S==0]\n",
    "print(YF.shape,YH.shape)\n",
    "\n",
    "XF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 3s 8ms/step - loss: 2.2830 - main_output_loss: 2.2833 - adversary_output_loss: 3.1513 - main_output_accuracy: 0.4115 - adversary_output_auc: 0.4724 - val_loss: 1.6796 - val_main_output_loss: 1.6804 - val_adversary_output_loss: 7.5507 - val_main_output_accuracy: 0.5591 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 1.6250 - main_output_loss: 1.6265 - adversary_output_loss: 15.6673 - main_output_accuracy: 0.5599 - adversary_output_auc: 0.5000 - val_loss: 1.3585 - val_main_output_loss: 1.3612 - val_adversary_output_loss: 26.4842 - val_main_output_accuracy: 0.6147 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 1s 6ms/step - loss: 1.3886 - main_output_loss: 1.3927 - adversary_output_loss: 40.6770 - main_output_accuracy: 0.6095 - adversary_output_auc: 0.5000 - val_loss: 1.1891 - val_main_output_loss: 1.1950 - val_adversary_output_loss: 58.2024 - val_main_output_accuracy: 0.6466 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 1.2575 - main_output_loss: 1.2652 - adversary_output_loss: 77.1387 - main_output_accuracy: 0.6436 - adversary_output_auc: 0.5000 - val_loss: 1.0773 - val_main_output_loss: 1.0875 - val_adversary_output_loss: 101.9729 - val_main_output_accuracy: 0.6816 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 1s 6ms/step - loss: 1.1508 - main_output_loss: 1.1635 - adversary_output_loss: 127.5595 - main_output_accuracy: 0.6638 - adversary_output_auc: 0.5000 - val_loss: 0.9942 - val_main_output_loss: 1.0101 - val_adversary_output_loss: 158.8179 - val_main_output_accuracy: 0.7022 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 1.0755 - main_output_loss: 1.0944 - adversary_output_loss: 189.0694 - main_output_accuracy: 0.6797 - adversary_output_auc: 0.5000 - val_loss: 0.9361 - val_main_output_loss: 0.9593 - val_adversary_output_loss: 231.6077 - val_main_output_accuracy: 0.7135 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 1.0199 - main_output_loss: 1.0463 - adversary_output_loss: 264.1634 - main_output_accuracy: 0.6932 - adversary_output_auc: 0.5000 - val_loss: 0.8884 - val_main_output_loss: 0.9193 - val_adversary_output_loss: 308.5648 - val_main_output_accuracy: 0.7251 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 2s 6ms/step - loss: 0.9719 - main_output_loss: 1.0073 - adversary_output_loss: 353.5570 - main_output_accuracy: 0.7002 - adversary_output_auc: 0.5000 - val_loss: 0.8498 - val_main_output_loss: 0.8904 - val_adversary_output_loss: 406.9194 - val_main_output_accuracy: 0.7277 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.9323 - main_output_loss: 0.9774 - adversary_output_loss: 451.4019 - main_output_accuracy: 0.7129 - adversary_output_auc: 0.5000 - val_loss: 0.8102 - val_main_output_loss: 0.8618 - val_adversary_output_loss: 516.4464 - val_main_output_accuracy: 0.7362 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 1s 6ms/step - loss: 0.8811 - main_output_loss: 0.9386 - adversary_output_loss: 574.8298 - main_output_accuracy: 0.7208 - adversary_output_auc: 0.5000 - val_loss: 0.7724 - val_main_output_loss: 0.8372 - val_adversary_output_loss: 648.1527 - val_main_output_accuracy: 0.7465 - val_adversary_output_auc: 0.5000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 1s 3ms/step - loss: 0.0360 - main_output_loss: 0.8787 - adversary_output_loss: 1685.4054 - main_output_accuracy: 0.7356 - adversary_output_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "evaluation = model.evaluate(X_test, {'main_output': Y_test, 'adversary_output': S_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607/607 [==============================] - 1s 2ms/step\n",
      "261/261 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract shared representation model\n",
    "representation_model = Model(inputs=model.input, outputs=model.get_layer('shared_representation').output)\n",
    "\n",
    "# Transform X_train and X_test\n",
    "X_train_transformed_2 = representation_model.predict(X_train)\n",
    "X_test_transformed_2 = representation_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on transformed test data: 0.7577177177177177\n",
      "\n",
      "final 0.7319076217263948\n",
      "macro_fscore 0.6526436809324047\n",
      "1-eval_scores 0.8111715625203849\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train a new classifier on the transformed training data\n",
    "clf_2 = LogisticRegression(max_iter=5000)  # Increase max_iter if needed for convergence\n",
    "history_new_2 = clf_2.fit(X_train_transformed_2, Y_train)  # Y_train are your original training labels\n",
    "\n",
    "# Step 3: Predict on the transformed test data and evaluate\n",
    "Y_pred_2 = clf_2.predict(X_test_transformed_2)\n",
    "accuracy_2= accuracy_score(Y_test, Y_pred_2)  # Y_test are your original test labels\n",
    "print(f\"Accuracy on transformed test data: {accuracy_2}\")\n",
    "\n",
    "# Step 4 : Predict with gloabl score\n",
    "eval_scores_2, confusion_matrices_eval_2 = gap_eval_scores(Y_pred_2, Y_test, S_test, metrics=['TPR'])\n",
    "final_score_2 = (eval_scores_2['macro_fscore']+ (1-eval_scores_2['TPR_GAP']))/2\n",
    "print('\\nfinal',final_score_2)\n",
    "print('macro_fscore',eval_scores_2['macro_fscore'])\n",
    "print('1-eval_scores',1-eval_scores_2['TPR_GAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:06:17.056611: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at reduction_ops_common.h:147 : INVALID_ARGUMENT: Invalid reduction dimension (0 for input with 0 dimension(s)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Mean_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (0 for input with 0 dimension(s) [Op:Mean] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m classwise_loss(Y_test, Y_pred_2)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclasswise_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_pred_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 24\u001b[0m, in \u001b[0;36mclasswise_accuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     20\u001b[0m class_accuracies \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mequal(y_true_classes, y_pred_classes), tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Reduce across all dimensions but the first (batch dimension)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# to get accuracy per class, then take the mean across classes\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m classwise_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_accuracies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m overall_acc \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(classwise_acc)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m overall_acc\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Mean_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (0 for input with 0 dimension(s) [Op:Mean] name: "
     ]
    }
   ],
   "source": [
    "classwise_loss(Y_test, Y_pred_2)\n",
    "classwise_accuracy(Y_test, Y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def classwise_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric function that calculates the accuracy for each class individually\n",
    "    and then averages these accuracies.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Tensor of true labels, one-hot encoded.\n",
    "        y_pred: Tensor of predicted labels, as probabilities.\n",
    "\n",
    "    Returns:\n",
    "        A scalar tensor representing the average class-wise accuracy.\n",
    "    \"\"\"\n",
    "    # Convert probabilities to predicted class (highest probability)\n",
    "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
    "    y_true_classes = tf.argmax(y_true, axis=-1)\n",
    "    \n",
    "    # Calculate accuracy for each class\n",
    "    class_accuracies = tf.cast(tf.equal(y_true_classes, y_pred_classes), tf.float32)\n",
    "    \n",
    "    # Reduce across all dimensions but the first (batch dimension)\n",
    "    # to get accuracy per class, then take the mean across classes\n",
    "    classwise_acc = tf.reduce_mean(class_accuracies, axis=0)\n",
    "    overall_acc = tf.reduce_mean(classwise_acc)\n",
    "    \n",
    "    return overall_acc\n",
    "\n",
    "# Example usage with a model compilation in TensorFlow/Keras\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[classwise_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
