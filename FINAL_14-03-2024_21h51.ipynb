{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSE DU PROBLEME**\n",
    "---\n",
    "\n",
    "Problème de classification (28 classes) avec évaluation \"sur mesure\" (composite) qui tient compte de la performance et de l'équité du modèle<br><br>. \n",
    "\n",
    "Jeu de donnée de 25.000 personnes, après voir lancé la baseline, j'ai entrainé un **adversarial NN**, qui permettait de gagner un peu d'équité (passage de 80% à 85% sur le TRP gap) mais a entrainé un éffondrement de l'accuracy (de 65% à 35%). après avoir cherché à personaliser la fonction de perte (avec difficulté pour entrainer le modele), je suis repassée à une approche plus progressive, sur la régression logistique\n",
    "\n",
    "**regression logisitique (baseline) => 3 problemes**<br>\n",
    "1. ***l'échantillonage*** : Le \"train_test_split\" ne tient pas compte de S, nous ne savons pas si l'attribut protégé (H/F) est bien réparti entre X_train et X_test, cela n'est pas optimum pour l'apprentissage car certaines classes contiennent peu de points. Il peut aussi etre plus pertinent de fixer les hyperparametre grace à X_train, et d'entrainer le modele sur tout l'échantillon (avec les memes hyperparametres) avant de prédire X_test_true et de soumettre<br>\n",
    "=> nous réaliserons des train_test_split en tenant compte de X et Y grace à Y56 = Y + 28*S <br>\n",
    "=> nous ferons des soumissions double (modele appris sur X_train et aussi X) pour le datachallenge, pour améliorer les qualités prédicitive du modèles <br><br>\n",
    "2. la fonction d'évaluation est une ***moyenne de scores calculé par classes***, chaque classe a donc le meme poids dans le score final. Or, l'apprentissage est fait pour optimser l'accuracy de l'échantillon (chaque élément à le meme poids). Comme la distribution de l'échatillon est très mal équilibrée entre les classes (93 à 8.285 personnes), le modèle ne peut apprendre correctement<br>\n",
    "=> nous essaierons pour la forme del a data augmentation, mais sans conviction compte tenu de l'embedding sémantique fait avec BERT<br>\n",
    "=> nous utiliserons une correction de la fonction de pertes pour y inclure le poids de chaque classe (Y et Y56)<br>\n",
    "=> nous essaierons du contrastive learning pour obtenir un espace de réprésentation adéquat<br><br>\n",
    "2. ***l'apprentissage n'est pas optimal (alignement et hyperparametres à améliorer)***. Il manque la régularization et du cross validation. L'apprentissage ,'est pas aligné avec \"score final\": le modele fait pour optimiser l'accuracy (la précision), or la fonction d'évaluation est une moyenne entre le F1 score (moyenne harmonique de la précision et du rappel) et une métrique de fairness. Le F1 score pénalise les écarts importants entre la précision et le rappel. Le score<br>\n",
    "=> nous adapterons le fonctions de pertes et/ou l'architecture des modèles intégrer au mieux notrescore final\n",
    "=> nous ajouterons systematiquement des termes de régularisations et de cross validation (stratified k-fold cross validation si possibl)<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHODOLOGIE**\n",
    "---\n",
    "\n",
    "**Nous allons procéder en 4 temps** :\n",
    "\n",
    "**1/ optimiser la régression logisitique**<br>\n",
    "<br>\n",
    "ajouter double prédiction sur S et nonS<br><br>\n",
    "\n",
    "**2/ débiaiser l'échantillon**<br> \n",
    "\n",
    "\n",
    "**3/ personaliser la foncition de perts**\n",
    "\n",
    "**4/ explorer modeles précis à la frontiere**<br>\n",
    "KNN\n",
    "SVM linéaire et gaussien\n",
    "1 versus all sur classe mal prédites\n",
    "\n",
    "**5/ regression linéaire des modèles**\n",
    "échantilloner X par rapport à Y et S** traiter le probleme 1 et 2, en créant un label à 56 classes (2 x 28) pour distinguer chaque label i en fonction de s'il est protégé ou non. Nous augmenterons la taille de l'échantillon (avec 56 labels) pour créer X_XL et Y_XL pour avoir le meme nombre d'items pour chacune des 56 classes et un jeu avec le meme nombre d'instance par classe, permettant d'aligner les scores moyens des classes avec la moyenne du nouveau sample \"XL\" décuplé (passage de 27.749 lignes à 255.304 lignes ). Nous programmerons la régression logisitique avec pytorch pour accélérer les calculs.\n",
    "\n",
    "2/ nous **ajusterons ensuite la fonction de pertes**, pour qu'elle tienne compte au mieux de la fonction d'évaluation, qui est composée de 2 éléments : le F1 score et le 1-equal ooprtunity gap<br>\n",
    "- le 'macro f score' (F1 score) n'est pas dérivable (à valider), nous l'approcherons donc par accuracy et le recall<br>\n",
    "- true positive gap : 1 - TRP_GAP est calculé comme \n",
    "A noter que le F1 score n'est pas dérivable. However, we can approximate the F1 score in a differentiable manner by using the ***Sørensen–Dice coefficient***, which is closely related to the F1 score and is differentiable. The Sørensen–Dice coefficient is defined as \\(2 * \\frac{precision * recall}{precision + recall}\\), which is equivalent to the F1 score formula. For a differentiable approximation, we can use soft versions of precision and recall.\n",
    "<br><br>\n",
    "\n",
    "3/ Nous explorerons **différents modèles de classification** K-means, SVM, random forest tree<br><br>\n",
    "\n",
    "4/ Avant de mener cette approche j'avais essayer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) Import, loading data, eval functions**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import make_scorer #, f1_score\n",
    "\n",
    "#from Data_challenge_fairness_2024.evaluator import *\n",
    "from evaluator import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_model = 'FINAL_models/'  # must finish by '/'\n",
    "path_Y_pred_true = 'FINAL_Y_pred_true/'  # must finish by '/'\n",
    "\n",
    "# with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)\n",
    "# with open(path_model + name + '.pkl', 'rb') as f: model = pickle.load(f)\n",
    "\n",
    "def get_final_score(Y_pred, Y, S):\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "    final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "    return final_score\n",
    "    \n",
    "    \n",
    "def get_scores(Y_pred, Y, S):\n",
    "    accuracy= accuracy_score(Y, Y_pred)  # Y_test are your original test labels\n",
    "    print(f\"Accuracy on transformed test data: {accuracy}\")\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "    final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "    macro_f1 = eval_scores['macro_fscore']\n",
    "    inv_macro_gap = 1-eval_scores['TPR_GAP']\n",
    "\n",
    "    #print results\n",
    "    print('final score :',final_score)\n",
    "    print('macro_f1    :',eval_scores['macro_fscore'])\n",
    "    print('inv_macro_gap',1-eval_scores['TPR_GAP'])\n",
    "    \n",
    "    return accuracy, final_score, macro_f1, inv_macro_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'X_test', 'Y', 'S_train', 'S_test'])\n",
      "(27749, 768) (27749,) (27749,) (11893, 768) (11893,)\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Load pickle file and convert to numpy array\n",
    "#####################################################\n",
    "\n",
    "with open('data-challenge-student.pickle', 'rb') as handle:\n",
    "    # dat = pickle.load(handle)\n",
    "    dat = pd.read_pickle(handle)\n",
    "\n",
    "#Check keys()\n",
    "print(dat.keys())\n",
    "X = dat['X_train']\n",
    "Y = dat['Y']\n",
    "S = dat['S_train']\n",
    "\n",
    "X_test_true = dat['X_test']\n",
    "S_test_true = dat['S_test']\n",
    "\n",
    "Y56= Y + 28*S\n",
    "#X, X_test,Y,S, S_test = dat[1]\n",
    "\n",
    "print(X.shape,Y.shape,S.shape,X_test_true.shape,S_test_true.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, S_train, S_test = train_test_split(X, Y, S, test_size=0.3, random_state=42)\n",
    "\n",
    "path_model = 'FINAL_models/'\n",
    "path_Y_pred_true = 'FINAL_Y_pred_true/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#   DEBIASING X : CREATION OF ORTHOGONAL PROJECTION \n",
    "################################################################\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Bias estimation in dataset\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Calculate average embedding for group sensitive (S=1) and non sensitive (S=0)\n",
    "X_sensitive = X[S==1]\n",
    "X_sensitive_mean=X_sensitive.mean()\n",
    "\n",
    "X_non_sensitive = X[S!=1]\n",
    "X_non_sensitive_mean=X_non_sensitive.mean()\n",
    "\n",
    "bias = X_sensitive_mean-X_non_sensitive_mean\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# function to debiase data\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "def remove_bias(dataset, bias):\n",
    "    ''' orthogonal projection of dataset / bias'''\n",
    "    # Compute the dot product of each row of the dataset with diff\n",
    "    dot_products = np.dot(dataset, bias)\n",
    "    \n",
    "    # Compute the magnitude of bias\n",
    "    bias_magnitude_squared = np.dot(bias, bias)\n",
    "    \n",
    "    # Compute the projection of each row onto diff\n",
    "    projection = np.outer(dot_products / bias_magnitude_squared, bias)\n",
    "    \n",
    "    # Subtract the projection from the dataset\n",
    "    debiased_dataset = dataset - projection\n",
    "    \n",
    "    return debiased_dataset\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Debiased X and X_test_true\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "debiased_X = remove_bias(X, bias)\n",
    "debiased_X_test_true = remove_bias(X_test_true, bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION MODELS**\n",
    "---\n",
    "<br>\n",
    "0_Baseline : logistic regression (on X_train)<br><br>\n",
    "1_Optimised : optimized logistic regression (on X + hyperparameters+ stratified k-fold cross validation)<br><br>\n",
    "2_Stratified K fold Logistic Regression\n",
    "3_Orthogonal debiasing of X on model 2 (Optimised Logisitic regression with custom loss function) <br><br>\n",
    "4_Orthogonal debiasing of X on MAN/WOMAN embedding difference  on model 2 (Optimised Logisitic regression with custom loss function) <br><br>\n",
    "5_Custom loss fonctin on Optimised Logisitic regression (56 classes with Y56= Y + 28*S) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = pd.DataFrame(columns=['Model','Accuracy','final score','Fscore macro','1 - TPR gap'])\n",
    "RESULTS.loc[0]=['baseline (Reglog28)',accuracy_0,final_score_0, eval_scores_0['macro_fscore'],1-eval_scores_0['TPR_GAP']]\n",
    "RESULTS.loc[2]=['RegLog28 + YxS',accuracy_1,final_score_1, eval_scores_1['macro_fscore'],1-eval_scores_1['TPR_GAP']]\n",
    "RESULTS.loc[4]=['RegLog28 + XL',accuracy_2,final_score_2, eval_scores_2['macro_fscore'],1-eval_scores_2['TPR_GAP']]\n",
    "RESULTS.loc[5]=['RegLog28 + YxS + XL',accuracy_3,final_score_3, eval_scores_3['macro_fscore'],1-eval_scores_3['TPR_GAP']]\n",
    "RESULTS.loc[6]=['RegLog56 + YxS + XL',accuracy_4,final_score_4, eval_scores_4['macro_fscore'],1-eval_scores_4['TPR_GAP']]\n",
    "RESULTS.loc[3]=['RegLog56 + YxS',accuracy_5,final_score_5, eval_scores_5['macro_fscore'],1-eval_scores_5['TPR_GAP']]\n",
    "RESULTS.loc[1]=['baseline seed=1 (Reglog28)',accuracy_0_1,final_score_0_1, eval_scores_0_1['macro_fscore'],1-eval_scores_0_1['TPR_GAP']]\n",
    "RESULTS = RESULTS.sort_index()\n",
    "RESULTS\n",
    "\n",
    "with open('RESULTS_10-03-2024.pkl', 'wb') as f:\n",
    "   pickle.dump(RESULTS, f)\n",
    "\n",
    "#RESULTS =  pd.read_pickle('RESULTS_10-03-2024.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on transformed test data: 0.7638438438438439\n",
      "final score : 0.7365033273594812\n",
      "macro_f1    : 0.669337208333607\n",
      "inv_macro_gap 0.8036694463853555\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# 0. LOGISTIC REGRESSION - BASELINE \n",
    "###############################################\n",
    "\n",
    "name ='0_Reglog_baseline' # changer clf_i\n",
    "\n",
    "# Refresh training data\n",
    "X_train, X_test, Y_train, Y_test, S_train, S_test = train_test_split(X, Y, S, test_size=0.3, random_state=42)\n",
    "\n",
    "# training (or load)logistic model\n",
    "#clf_0 = LogisticRegression(random_state=0, max_iter=5000,verbose=1).fit(X_train, Y_train)\n",
    "with open(path_model + name + '.pkl', 'rb') as f: clf_0 = pickle.load(f)\n",
    "model = clf_0 \n",
    "  \n",
    "# predicting and assessing\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "Y_pred_true = model.predict(X_test_true)\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        21532     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.24653D+04    |proj g|=  4.11128D+04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.05318D+04    |proj g|=  8.07961D+02\n",
      "\n",
      "At iterate  100    f=  1.73620D+04    |proj g|=  6.71832D+02\n",
      "\n",
      "At iterate  150    f=  1.61758D+04    |proj g|=  1.03107D+02\n",
      "\n",
      "At iterate  200    f=  1.57705D+04    |proj g|=  1.24845D+02\n",
      "\n",
      "At iterate  250    f=  1.56370D+04    |proj g|=  3.30421D+01\n",
      "\n",
      "At iterate  300    f=  1.55878D+04    |proj g|=  2.25705D+01\n",
      "\n",
      "At iterate  350    f=  1.55716D+04    |proj g|=  3.01638D+01\n",
      "\n",
      "At iterate  400    f=  1.55661D+04    |proj g|=  1.65593D+01\n",
      "\n",
      "At iterate  450    f=  1.55641D+04    |proj g|=  1.12923D+01\n",
      "\n",
      "At iterate  500    f=  1.55632D+04    |proj g|=  3.90256D+00\n",
      "\n",
      "At iterate  550    f=  1.55628D+04    |proj g|=  6.05409D+00\n",
      "\n",
      "At iterate  600    f=  1.55624D+04    |proj g|=  4.51413D+00\n",
      "\n",
      "At iterate  650    f=  1.55619D+04    |proj g|=  1.26648D+01\n",
      "\n",
      "At iterate  700    f=  1.55610D+04    |proj g|=  7.07335D+00\n",
      "\n",
      "At iterate  750    f=  1.55595D+04    |proj g|=  1.62580D+01\n",
      "\n",
      "At iterate  800    f=  1.55577D+04    |proj g|=  4.04886D+00\n",
      "\n",
      "At iterate  850    f=  1.55561D+04    |proj g|=  8.06942D+00\n",
      "\n",
      "At iterate  900    f=  1.55553D+04    |proj g|=  3.19503D+00\n",
      "\n",
      "At iterate  950    f=  1.55548D+04    |proj g|=  7.35077D+00\n",
      "\n",
      "At iterate 1000    f=  1.55546D+04    |proj g|=  5.86208D+00\n",
      "\n",
      "At iterate 1050    f=  1.55544D+04    |proj g|=  7.19974D+00\n",
      "\n",
      "At iterate 1100    f=  1.55543D+04    |proj g|=  1.86093D+00\n",
      "\n",
      "At iterate 1150    f=  1.55542D+04    |proj g|=  6.22605D+00\n",
      "\n",
      "At iterate 1200    f=  1.55540D+04    |proj g|=  1.72893D+00\n",
      "\n",
      "At iterate 1250    f=  1.55538D+04    |proj g|=  2.47744D+00\n",
      "\n",
      "At iterate 1300    f=  1.55534D+04    |proj g|=  1.54724D+01\n",
      "\n",
      "At iterate 1350    f=  1.55529D+04    |proj g|=  5.64675D+00\n",
      "\n",
      "At iterate 1400    f=  1.55524D+04    |proj g|=  7.40508D+00\n",
      "\n",
      "At iterate 1450    f=  1.55520D+04    |proj g|=  1.60392D+00\n",
      "\n",
      "At iterate 1500    f=  1.55519D+04    |proj g|=  3.46264D+00\n",
      "\n",
      "At iterate 1550    f=  1.55518D+04    |proj g|=  1.11544D+00\n",
      "\n",
      "At iterate 1600    f=  1.55518D+04    |proj g|=  7.54015D-01\n",
      "\n",
      "At iterate 1650    f=  1.55518D+04    |proj g|=  6.12268D-01\n",
      "\n",
      "At iterate 1700    f=  1.55518D+04    |proj g|=  1.06131D+00\n",
      "\n",
      "At iterate 1750    f=  1.55517D+04    |proj g|=  9.33577D-01\n",
      "\n",
      "At iterate 1800    f=  1.55517D+04    |proj g|=  6.66243D-01\n",
      "\n",
      "At iterate 1850    f=  1.55516D+04    |proj g|=  1.86799D+00\n",
      "\n",
      "At iterate 1900    f=  1.55516D+04    |proj g|=  1.80377D+00\n",
      "\n",
      "At iterate 1950    f=  1.55515D+04    |proj g|=  9.75567D-01\n",
      "\n",
      "At iterate 2000    f=  1.55515D+04    |proj g|=  4.66221D-01\n",
      "\n",
      "At iterate 2050    f=  1.55514D+04    |proj g|=  2.32000D+00\n",
      "\n",
      "At iterate 2100    f=  1.55514D+04    |proj g|=  1.20032D+00\n",
      "\n",
      "At iterate 2150    f=  1.55514D+04    |proj g|=  4.91983D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "21532   2176   2292      1     0     0   2.146D-01   1.555D+04\n",
      "  F =   15551.423405080426     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Accuracy on transformed test data: 0.856096096096096\n",
      "final score : 0.8207123104282983\n",
      "macro_f1    : 0.8407599159632768\n",
      "inv_macro_gap 0.8006647048933198\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# 1. LOGISTIC REGRESSION - BASELINE OPTIMISED\n",
    "# (no validation set - training on all X)\n",
    "##################################################\n",
    "\n",
    "name ='1_Reglog_optimised' # changer clf_i\n",
    "\n",
    "# Refresh training data\n",
    "# TRAINED ON ALL X\n",
    "\n",
    "# training (or load)logistic model\n",
    "# added regularisation 'l2' with coeff 0.2 (C) and early stopping with tol = 0.0001\n",
    "# clf_1 = LogisticRegression(random_state=42, max_iter=5000,verbose=1,penalty='l2', C=0.2, tol=0.0001).fit(X, Y)\n",
    "with open(path_model + name + '.pkl', 'rb') as f: clf_1 = pickle.load(f)\n",
    "model = clf_1\n",
    "\n",
    "# predicting and assessing\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "Y_pred_true = model.predict(X_test_true)\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on transformed test data: 0.856096096096096\n",
      "final score : 0.8207123104282983\n",
      "macro_f1    : 0.8407599159632768\n",
      "inv_macro_gap 0.8006647048933198\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# 2. LOGISTIC REGRESSION - STRATIFIED K-FOLD\n",
    "# on optimized Log. Reg. regularisatio, early stoppping\n",
    "# (no validation set - training on all X)\n",
    "##################################################\n",
    "\n",
    "name ='2_Reglog_StratKFold' # changer clf_i\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Refresh training data\n",
    "# TRAINED ON ALL X\n",
    "\n",
    "# training (or load)logistic model\n",
    "# added regularisation 'l2' with coeff 0.2 (C) and early stopping with tol = 0.0001\n",
    "clf_2 = LogisticRegression(random_state=42, max_iter=5000,verbose=0,penalty='l2', C=0.2, tol=0.0001)\n",
    "\n",
    "# Préparer la validation croisée k-fold stratifiée\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "scores = cross_val_score(clf_2, X, Y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "clf_2.fit(X, Y)\n",
    "model = clf_2\n",
    "# with open(path_model + name + '.pkl', 'rb') as f: clf_1 = pickle.load(f)\n",
    "\n",
    "# predicting and assessing\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "Y_pred_true = model.predict(X_test_true)\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on transformed test data: 0.8545345345345345\n",
      "final score : 0.8290222283482765\n",
      "macro_f1    : 0.8381637333117026\n",
      "inv_macro_gap 0.8198807233848505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaele/myenv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.3.2 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# 3. DEBIASING WITH ORTHOGONAL PROJECTION + OPTIMISED MODEL \n",
    "# (using the vector of the average difference of embedding between groups \n",
    "# to debiase representation of X, by operating an orthogonal projection)\n",
    "##########################################################################\n",
    "\n",
    "name ='3_Reglog_Optimized_orthogonal' # changer clf_i\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Debiasing X (Projection of X orthogonally to bias) \n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# projection in new representation space\n",
    "debiased_X = remove_bias(X, bias)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# TRAINING MODEL AND PREDICTING\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# clf_3 = LogisticRegression(random_state=0, max_iter=5000,verbose=0,penalty='l2', C=0.2, tol=0.0001).fit(debiased_X, Y)\n",
    "with open(path_model + name + '.pkl', 'rb') as f: clf_3 = pickle.load(f)\n",
    "model = clf_3\n",
    "\n",
    "# predicting and assessing\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "debiased_X_test_true = remove_bias(X_test_true, bias)  # debiasing\n",
    "Y_pred_true = model.predict(debiased_X_test_true)\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "\n",
    "#\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12793, 768) (14956, 768)\n",
      "(12793,) (14956,)\n",
      "(12793,) (14956,)\n",
      "Accuracy on transformed test data: 0.8742342342342342\n",
      "final score : 0.8042258252858332\n",
      "macro_f1    : 0.865061187492607\n",
      "inv_macro_gap 0.7433904630790595\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "# 4. APPROCHE DUALE : MODEL HOMME + MODEL FEMME (DEBIASED X)\n",
    "# + Debiasing with orthogonal projection + Optimised Logisitic Regression\n",
    "##########################################################################\n",
    "\n",
    "name ='4_Reglog_DUAL_orthogonal_FxH' # changer clf_i\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PREPARATION DES DONNEES\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# generating samples for Woman (S=1) and Men (S=0)\n",
    "X_F , X_H = X[S==1] , X[S==0]\n",
    "Y_F , Y_H = Y[S==1] , Y[S==0]\n",
    "S_F , S_H = S[S==1] , S[S==0]\n",
    "X_test_true_F , X_test_true_H = X_test_true[S_test_true==1] , X_test_true[S_test_true==0]\n",
    "S_test_true_F , S_test_true_H = S_test_true[S_test_true==1] , S_test_true[S_test_true==0]\n",
    "# debiasing X and X_test_true\n",
    "\n",
    "debiased_X = remove_bias(X,bias)\n",
    "debiased_X_test = remove_bias(X_test,bias)\n",
    "debiased_X_test_true = remove_bias(X_test_true, bias)\n",
    "\n",
    "debiased_X_F , debiased_X_H = debiased_X[S==1] , debiased_X[S==0]\n",
    "debiased_X_test_F , debiased_X_test_H = debiased_X_test[S_test==1] , debiased_X_test[S_test==0]\n",
    "debiased_X_test_true_F , debiased_X_test_true_H = debiased_X_test_true[S_test_true==1] , debiased_X_test_true[S_test_true==0]\n",
    "print(X_F.shape,X_H.shape)\n",
    "print(Y_F.shape,Y_H.shape)\n",
    "print(S_F.shape,S_H.shape)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ENTRAINEMENT DES MODELES\n",
    "#-----------------------------------------------------\n",
    "\n",
    "'''# Prepare Logistic Regression models\n",
    "# model 4 # model_X = LogisticRegression(random_state=0, max_iter=5000,penalty='l2', C=0.2, tol=0.0001).fit(X,Y)\n",
    "model_F = LogisticRegression(random_state=0, max_iter=5000,penalty='l2', C=0.2, tol=0.0001)\n",
    "model_H = LogisticRegression(random_state=0, max_iter=5000, penalty='l2', C=0.2, tol=0.0001)\n",
    "\n",
    "# Train the models\n",
    "model_F.fit(debiased_X_F, Y_F)\n",
    "model_H.fit(debiased_X_H, Y_H)'''\n",
    "with open(path_model + name + '.pkl', 'rb') as f: clf_3 = pickle.load(f)\n",
    "model = clf_3\n",
    "\n",
    "# predicting and assessing on test\n",
    "Y_pred_F = model_F.predict(debiased_X_test_F)\n",
    "Y_pred_H = model_H.predict(debiased_X_test_H)\n",
    "# compute final result depending on S_test_true\n",
    "Y_pred_all = np.zeros(len(Y_test))\n",
    "Y_pred_all[ S_test == 1 ] = Y_pred_F\n",
    "Y_pred_all[ S_test == 0 ] = Y_pred_H\n",
    "# Y_pred_F * S_test + Y_pred_H * (1-S_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred_all,Y_test,S_test)\n",
    "\n",
    "# Predict model on test_true\n",
    "Y_pred_true_F = model_F.predict(debiased_X_test_true_F)\n",
    "Y_pred_true_H = model_H.predict(debiased_X_test_true_H)\n",
    "# compute final result depending on S_test_true\n",
    "Y_pred_true_all = np.zeros(len(X_test_true))\n",
    "Y_pred_true_all[ S_test_true == 1 ] = Y_pred_true_F\n",
    "Y_pred_true_all[ S_test_true == 0 ] = Y_pred_true_H\n",
    "# Y_pred_true_all = Y_pred_true_F * S_test_true + Y_pred_true_H * (1-S_test_true)\n",
    "\n",
    "results=pd.DataFrame(Y_pred_true_all, columns= ['score'])\n",
    "results['score'] = results['score'].astype(int)\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "#results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "#\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)\n",
    "with open(path_model + '4_Reglog_DUAL_orthogonal_F' + '.pkl', 'wb') as f: pickle.dump(model_F, f)\n",
    "with open(path_model + '4_Reglog_DUAL_orthogonal_H' + '.pkl', 'wb') as f: pickle.dump(model_H, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##########################################################################\\n# 4. BERT (WOMAN-MAN) DEBIASING WITH ORTHOGONAL PROJECTION + MODEL 2 (k-fold)\\n# (using the vector of the difference of embedding between WOMAN and MAN\\n# to debiase representation of X, by operating an orthogonal projection)\\n# !!!! uncertainty about model of BERT used for the training !!!!\\n##########################################################################\\n\\nname =\\'4_Reglog_StratKFold_orthogonalBERT\\' # changer clf_i\\n\\n#------------------------------------------------------------------------\\n# GET MAN AND WOMAN EMBEDDING IN BERT\\n#-----------------------------------------------------------------------\\n\\nfrom transformers import BertTokenizer, TFBertModel\\nimport tensorflow as tf\\nimport tokenizers as tk\\nfrom tqdm import tqdm\\n\\n# Charger le tokenizer et modèle de BERT\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-multilingual-cased\\')\\nmodel = TFBertModel.from_pretrained(\\'bert-base-multilingual-cased\\')\\n\\n# Tokenize \"man\" and \"woman\"\\ntokens_man = tokenizer.encode(\"man\", add_special_tokens=True)  # Ajoute les tokens spéciaux\\ntokens_woman = tokenizer.encode(\"woman\", add_special_tokens=True)\\n\\nprint(tokens_man)\\nprint(tokens_woman)\\n\\n# transforme en tensor de batch (meme si un seul mot)\\n\\ninput_ids_man = tf.constant(tokens_man)[None, :]  # Ajoute une dimension de batch\\ninput_ids_woman = tf.constant(tokens_woman)[None, :]  # Ajoute une dimension de batch\\n\\n# Obtenir les embeddings\\noutputs_man = model(input_ids_man)\\noutputs_woman = model(input_ids_woman)\\n\\n# Les embeddings du dernier layer pour le premier token (\\'[CLS]\\' par défaut)\\nembedding_man = outputs_man.last_hidden_state[0][0]\\nembedding_woman = outputs_woman.last_hidden_state[0][0]\\nbias_BERT = embedding_woman - embedding_man\\nbias_BERT = np.array (bias_BERT)\\nprint(embedding_man.shape)  # Doit être (768,)\\nprint(embedding_woman.shape)  # Doit être (768,)\\nprint(bias_BERT.shape)  # Doit être (768,)\\n\\n#---------------------------------------------------------------------\\n# Debiasing X (Projection of X orthogonally to bias) \\n#---------------------------------------------------------------------\\n\\n# projection in new representation space\\ndebiased_X_BERT = remove_bias(X, bias_BERT)\\n\\n#----------------------------------------------------------------------\\n# TRAINING MODEL AND PREDICTING\\n#------------------------------------------------------------------------\\n\\nclf_4 = LogisticRegression(random_state=42, max_iter=5000,verbose=1,penalty=\\'l2\\', C=0.2, tol=0.0001)\\n\\n# Préparer la procédure de validation croisée k-fold stratifiée\\ncv = StratifiedKFold(n_splits=10)\\n#custom_scorer = make_scorer(final_score_S)\\nscores = cross_val_score(clf_4, debiased_X_BERT, Y, cv=cv, n_jobs=-1)\\nclf_4.fit(debiased_X_BERT, Y)\\nmodel = clf_4\\n# with open(path_model + name + \\'.pkl\\', \\'rb\\') as f: clf_3 = pickle.load(f)\\n\\n# predicting and assessing\\nY_pred = model.predict(X_test)\\naccuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\\n\\n# predict X_test_true and save\\nmodified_X_test_true = remove_info(X_test_true, bias_BERT)  # debiasing\\nY_pred_true = model.predict(modified_X_test_true)\\nresults=pd.DataFrame(Y_pred_true, columns= [\\'score\\'])\\nresults.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\\n\\n# save model\\nwith open(path_model + name + \\'.pkl\\', \\'wb\\') as f: pickle.dump(model, f)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''##########################################################################\n",
    "# 4. BERT (WOMAN-MAN) DEBIASING WITH ORTHOGONAL PROJECTION + MODEL 2 (k-fold)\n",
    "# (using the vector of the difference of embedding between WOMAN and MAN\n",
    "# to debiase representation of X, by operating an orthogonal projection)\n",
    "# !!!! uncertainty about model of BERT used for the training !!!!\n",
    "##########################################################################\n",
    "\n",
    "name ='4_Reglog_StratKFold_orthogonalBERT' # changer clf_i\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# GET MAN AND WOMAN EMBEDDING IN BERT\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "import tokenizers as tk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Charger le tokenizer et modèle de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Tokenize \"man\" and \"woman\"\n",
    "tokens_man = tokenizer.encode(\"man\", add_special_tokens=True)  # Ajoute les tokens spéciaux\n",
    "tokens_woman = tokenizer.encode(\"woman\", add_special_tokens=True)\n",
    "\n",
    "print(tokens_man)\n",
    "print(tokens_woman)\n",
    "\n",
    "# transforme en tensor de batch (meme si un seul mot)\n",
    "\n",
    "input_ids_man = tf.constant(tokens_man)[None, :]  # Ajoute une dimension de batch\n",
    "input_ids_woman = tf.constant(tokens_woman)[None, :]  # Ajoute une dimension de batch\n",
    "\n",
    "# Obtenir les embeddings\n",
    "outputs_man = model(input_ids_man)\n",
    "outputs_woman = model(input_ids_woman)\n",
    "\n",
    "# Les embeddings du dernier layer pour le premier token ('[CLS]' par défaut)\n",
    "embedding_man = outputs_man.last_hidden_state[0][0]\n",
    "embedding_woman = outputs_woman.last_hidden_state[0][0]\n",
    "bias_BERT = embedding_woman - embedding_man\n",
    "bias_BERT = np.array (bias_BERT)\n",
    "print(embedding_man.shape)  # Doit être (768,)\n",
    "print(embedding_woman.shape)  # Doit être (768,)\n",
    "print(bias_BERT.shape)  # Doit être (768,)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Debiasing X (Projection of X orthogonally to bias) \n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# projection in new representation space\n",
    "debiased_X_BERT = remove_bias(X, bias_BERT)\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# TRAINING MODEL AND PREDICTING\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "clf_4 = LogisticRegression(random_state=42, max_iter=5000,verbose=1,penalty='l2', C=0.2, tol=0.0001)\n",
    "\n",
    "# Préparer la procédure de validation croisée k-fold stratifiée\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "#custom_scorer = make_scorer(final_score_S)\n",
    "scores = cross_val_score(clf_4, debiased_X_BERT, Y, cv=cv, n_jobs=-1)\n",
    "clf_4.fit(debiased_X_BERT, Y)\n",
    "model = clf_4\n",
    "# with open(path_model + name + '.pkl', 'rb') as f: clf_3 = pickle.load(f)\n",
    "\n",
    "# predicting and assessing\n",
    "Y_pred = model.predict(X_test)\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "modified_X_test_true = remove_info(X_test_true, bias_BERT)  # debiasing\n",
    "Y_pred_true = model.predict(modified_X_test_true)\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL 6 - ADPAPTING LOSS FUNCTION IN LOGISTIC REGRESSION (PYTORCH)**\n",
    "---\n",
    "1. Functions for Custom loss function (re-written in pytorch)\n",
    "2. Functions for Stratified K-fold and training batches\n",
    "3. Running Model 6\n",
    "4. Optimising Model 6 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PROBLEME SUR FINAL SCORE QUI DEPEND DE S, OR SICKIT LEARN NE GERE\\nPAS S DANS LA CROSS VALIDATION, LA LOSS FUNCTION PERSONALISEE NE PEUT \\nETRE CALCULEE  =======> CODAGE SUR PYTORCH\\n\\n##########################################################################\\n# 5. CUSTOM LOSS FUNCTION (Using stratified K + custom_scorer)\\n# + Debiasing with orthogonal projection + Optimised Logisitic Regression\\n##########################################################################\\n\\nname =\\'5_Reglog_StratKFold1_Orthogonal_CustomLoss\\' # changer clf_i\\n\\n#---------------------------------------------------------------------\\n# Debiasing X (Projection of X orthogonally to bias) \\n#---------------------------------------------------------------------\\n\\n# projection in new representation space\\ndebiased_X = remove_bias(X, bias)\\n\\n#------------------------------------------------------------------------\\n# CREATION OF CUSTOM LOSS FUNCTION (FINAL SCORE) \\n# -----------------------------------------------------------------------\\n\\n#It is not possible to split S with the stratified k-fold implementation \\n# in sickit learn. We will use Y56 = Y + 28*S to train logistic model\\n# and derive from Y56 the value of Y = Y56 % 28 and S = Y56//28\\n\\ndef final_score_S(Y,Y_pred):\\n    # wrapper function to include S\\n    # Note order : custom scorer expects (y_true, y_pred) as inputs\\n    \\n    return get_final_score(Y_pred,Y,S)\\n\\ncustom_scorer = make_scorer(final_score_S)\\n\\n#---------------------------------------------------------------------\\n# TRAINING MODEL AND PREDICTING\\n#---------------------------------------------------------------------\\n\\nclf_5 = LogisticRegression(random_state=0, max_iter=5000,verbose=0,penalty=\\'l2\\', C=0.2, tol=0.0001)\\n\\n# Préparer la procédure de validation croisée k-fold stratifiée\\ncv = StratifiedKFold(n_splits=1)\\nscores = cross_val_score(clf_3, debiased_X, Y, scoring=custom_scorer ,cv=cv, n_jobs=-1)\\nclf_5.fit(debiased_X, Y56)\\nmodel = clf_5\\n# with open(path_model + name + \\'.pkl\\', \\'rb\\') as f: clf_5 = pickle.load(f)\\n\\n# predicting and assessing\\nY56_pred = model.predict(X_test)\\n#S_pred = Y56//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\\nY_pred = Y56_pred % 28  # reste (original Y)   ex 33% 28 = classe 5\\naccuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\\n\\n# predict X_test_true and save\\nmodified_X_test_true = remove_info(X_test_true, bias)  # debiasing\\nY56_pred_true = model.predict(modified_X_test_true)\\nY_pred_true = Y56_pred_true % 28  # reste (original Y)   ex 33% 28 = classe 5\\nresults=pd.DataFrame(Y_pred_true, columns= [\\'score\\'])\\nresults.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\\n\\n# save model\\nwith open(path_model + name + \\'.pkl\\', \\'wb\\') as f: pickle.dump(model, f)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' PROBLEME SUR FINAL SCORE QUI DEPEND DE S, OR SICKIT LEARN NE GERE\n",
    "PAS S DANS LA CROSS VALIDATION, LA LOSS FUNCTION PERSONALISEE NE PEUT \n",
    "ETRE CALCULEE  =======> CODAGE SUR PYTORCH\n",
    "\n",
    "##########################################################################\n",
    "# 5. CUSTOM LOSS FUNCTION (Using stratified K + custom_scorer)\n",
    "# + Debiasing with orthogonal projection + Optimised Logisitic Regression\n",
    "##########################################################################\n",
    "\n",
    "name ='5_Reglog_StratKFold1_Orthogonal_CustomLoss' # changer clf_i\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Debiasing X (Projection of X orthogonally to bias) \n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# projection in new representation space\n",
    "debiased_X = remove_bias(X, bias)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# CREATION OF CUSTOM LOSS FUNCTION (FINAL SCORE) \n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "#It is not possible to split S with the stratified k-fold implementation \n",
    "# in sickit learn. We will use Y56 = Y + 28*S to train logistic model\n",
    "# and derive from Y56 the value of Y = Y56 % 28 and S = Y56//28\n",
    "\n",
    "def final_score_S(Y,Y_pred):\n",
    "    # wrapper function to include S\n",
    "    # Note order : custom scorer expects (y_true, y_pred) as inputs\n",
    "    \n",
    "    return get_final_score(Y_pred,Y,S)\n",
    "\n",
    "custom_scorer = make_scorer(final_score_S)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# TRAINING MODEL AND PREDICTING\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "clf_5 = LogisticRegression(random_state=0, max_iter=5000,verbose=0,penalty='l2', C=0.2, tol=0.0001)\n",
    "\n",
    "# Préparer la procédure de validation croisée k-fold stratifiée\n",
    "cv = StratifiedKFold(n_splits=1)\n",
    "scores = cross_val_score(clf_3, debiased_X, Y, scoring=custom_scorer ,cv=cv, n_jobs=-1)\n",
    "clf_5.fit(debiased_X, Y56)\n",
    "model = clf_5\n",
    "# with open(path_model + name + '.pkl', 'rb') as f: clf_5 = pickle.load(f)\n",
    "\n",
    "# predicting and assessing\n",
    "Y56_pred = model.predict(X_test)\n",
    "#S_pred = Y56//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "Y_pred = Y56_pred % 28  # reste (original Y)   ex 33% 28 = classe 5\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "# predict X_test_true and save\n",
    "modified_X_test_true = remove_info(X_test_true, bias)  # debiasing\n",
    "Y56_pred_true = model.predict(modified_X_test_true)\n",
    "Y_pred_true = Y56_pred_true % 28  # reste (original Y)   ex 33% 28 = classe 5\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# 5. CUSTOM LOSS FUNCTION WITH 56 CLASS CLASSIFIER (USING Y56 = Y + S*28)\n",
    "# + Debiasing with orthogonal projection + Optimised Logisitic Regression\n",
    "##########################################################################\n",
    "\n",
    "name ='5_Reglog56_StratKFold_Orthogonal_CustomLoss' # changer clf_i\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Debiasing X (Projection of X orthogonally to bias) \n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# projection in new representation space\n",
    "debiased_X = remove_bias(X, bias)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# CREATION OF CUSTOM LOSS FUNCTION (FINAL SCORE) \n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "#It is not possible to split S with the stratified k-fold implementation \n",
    "# in sickit learn. We will use Y56 = Y + 28*S to train logistic model\n",
    "# and derive from Y56 the value of Y = Y56 % 28 and S = Y56//28\n",
    "\n",
    "def final_score_S(Y56,Y_pred):\n",
    "    '''custom scorer expects (y_true, y_pred) as inputs\n",
    "    Inputs : Y56 and Y pred\n",
    "    Outputs : final score on 28 classes with Y56 trick (S=Y56//28 and Y=Y56%28)'''\n",
    "    S = Y56//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "    Y = Y56 % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "    return get_final_score(Y_pred,Y,S)\n",
    "\n",
    "custom_scorer = make_scorer(final_score_S)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# TRAINING MODEL AND PREDICTING\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "'''BlockingIOErrorclf_5 = LogisticRegression(random_state=42, max_iter=5000,verbose=0,penalty='l2', C=0.2, tol=0.0001)\n",
    "\n",
    "# Préparer la procédure de validation croisée k-fold stratifiée\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "scores = cross_val_score(clf_5, debiased_X, Y56, scoring=custom_scorer ,cv=cv, n_jobs=-1)\n",
    "clf_5.fit(debiased_X, Y56)'''\n",
    "# with open(path_model + name + '.pkl', 'rb') as f: clf_5 = pickle.load(f)\n",
    "model = clf_5\n",
    "\n",
    "# predicting and assessing\n",
    "Y56_pred = model.predict(X_test)\n",
    "#S_pred = Y56//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "Y_pred = Y56_pred % 28  # reste (original Y)   ex 33% 28 = classe 5\n",
    "accuracy, final_score, macro_f1, inv_macro_gap = get_scores(Y_pred,Y_test,S_test)\n",
    "\n",
    "\n",
    "# predict X_test_true and save\n",
    "modified_X_test_true = remove_bias(X_test_true, bias)  # debiasing\n",
    "Y56_pred_true = model.predict(modified_X_test_true)\n",
    "Y_pred_true = Y56_pred_true % 28  # reste (original Y)   ex 33% 28 = classe 5\n",
    "results=pd.DataFrame(Y_pred_true, columns= ['score'])\n",
    "results.to_csv(path_Y_pred_true + \"Data_Challenge_\" + name + \".csv\", header = None, index = None)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# 6. CUSTOM LOSS FUNCTION IN PYTORCH (CLASSIFIER ON 28 ORIGINAL CLASSES)\n",
    "# + Debiasing with orthogonal projection + Optimised Logisitic Regression\n",
    "##########################################################################\n",
    "\n",
    "name ='5_Reglog56_StratKFold_Orthogonal_CustomLoss' # changer clf_i\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "#     CUSTOM LOSS FUNCTION AND EVALUATION FUNCTIONS\n",
    "#         (RE-WRITTEN FOR PYTORCH)\n",
    "#\n",
    "#   soft_f1_loss\n",
    "#   macro_soft_f1_loss\n",
    "#   get_macro_f1\n",
    "#   get_tpr_gap\n",
    "#   get_macro_tpr_gap\n",
    "#   soft_final_score_loss\n",
    "#   get_final_score\n",
    "#\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "def soft_macro_f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Differentiable approximation of the macro F1 score as a loss function.\n",
    "    Calculates the F1 score for each class independently and then takes the average.\n",
    "    Inputs :\n",
    "        y_true must be one hot encoded\n",
    "    \"\"\"\n",
    "    y_pred_one_hot = torch.nn.functional.one_hot(y_pred, num_classes=Y_train.nunique()) if len(y_pred.shape) == 1 else y_pred\n",
    "    #y_pred_probs = torch.softmax(y_pred_one_hot, dim=1)\n",
    "    \n",
    "    tp = torch.sum(y_true * y_pred, dim=0)\n",
    "    pp = torch.sum(y_pred, dim=0)\n",
    "    ap = torch.sum(y_true, dim=0)\n",
    "    \n",
    "    precision = tp / (pp + 1e-6)\n",
    "    recall = tp / (ap + 1e-6)\n",
    "    \n",
    "    f1_per_class = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    macro_f1 = torch.mean(f1_per_class)   # Mean to aggregate over all classes\n",
    "    \n",
    "    loss = 1 - macro_f1  # Minimizing loss is maximizing macro F1 score\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_macro_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the exact macro F1 score for evaluation.\n",
    "    Input : any format as tensors will be converted to Tensors of true label if dim >1 . Can be :\n",
    "        - Tensor of probabilities(y_pred_probs) dimension (n,28)\n",
    "        - Tensor of labels, one hote encoded (y_pred_one_hot) dimension (n,28)\n",
    "        - Tensor of labels (y_pred_tensor) dimension (n,1)\n",
    "    Ouput : scalar\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "\n",
    "    \" predict macro f1\"\n",
    "    f1 = f1_score(y_true_labels.cpu().numpy(), y_pred_labels.cpu().numpy(), average='macro')\n",
    "    return f1\n",
    "\n",
    "def get_tpr_gap(y_true, y_pred, protected_attribute, class_idx):\n",
    "    \"\"\"\n",
    "    Calculate the TPR gap for a specific class across protected groups.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred_probs: Tensor of predicted probabilities (after softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    - class_idx: Index of the class for which to calculate the TPR gap.\n",
    "    \n",
    "    Returns:\n",
    "    - TPR gap for the specified class.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "    \n",
    "    # Calculate overall TPR for the current class\n",
    "    overall_mask = y_true_labels == class_idx\n",
    "    overall_tpr = torch.sum((y_pred_labels == class_idx) & overall_mask).float() / (torch.sum(overall_mask).float() + 1e-6)\n",
    "    \n",
    "    # Initialize list to store TPR for each protected group\n",
    "    group_tprs = []\n",
    "    \n",
    "    # Calculate TPR for each protected group\n",
    "    for group_val in protected_attribute.unique():\n",
    "        group_mask = (protected_attribute == group_val) & overall_mask\n",
    "        group_tpr = torch.sum((y_pred_labels == class_idx) & group_mask).float() / (torch.sum(group_mask).float() + 1e-6)\n",
    "        group_tprs.append(group_tpr)\n",
    "    \n",
    "    # Calculate TPR gap for the current class\n",
    "    tpr_gaps = torch.abs(torch.tensor(group_tprs) - overall_tpr)\n",
    "    \n",
    "    return torch.mean(tpr_gaps)  # Return the mean TPR gap for this class\n",
    "\n",
    "def get_macro_tpr_gap(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Calculate the average TPR gap per class by calling tpr_gap for each class.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: Tensor of true labels, one-hot encoded.\n",
    "    - y_pred: Tensor of predicted logits (before softmax).\n",
    "    - protected_attribute: Tensor indicating group membership for each instance.\n",
    "    \n",
    "    Returns:\n",
    "    - Average TPR gap across all classes.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "    \n",
    "    # Initialize list to store TPR gaps for all classes\n",
    "    class_tpr_gaps = []\n",
    "    \n",
    "    # Iterate over each class\n",
    "    num_classes = len(y_true_labels.unique())\n",
    "    for class_idx in range(num_classes):\n",
    "        class_tpr_gap = get_tpr_gap(y_true_labels, y_pred_labels, protected_attribute, class_idx)\n",
    "        class_tpr_gaps.append(class_tpr_gap)\n",
    "    \n",
    "    # Calculate the average TPR gap across all classes\n",
    "    avg_tpr_gap = torch.mean(torch.stack(class_tpr_gaps))\n",
    "    \n",
    "    return avg_tpr_gap\n",
    "\n",
    "\n",
    "def soft_final_score_loss(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Combine soft macro F1 score and TPR gap to create a final evaluation metric.\n",
    "    \"\"\"\n",
    "    soft_macro_f1 = soft_macro_f1_loss(y_true, y_pred)  # Calculate soft macro F1 score\n",
    "    macro_tpr_gap = get_macro_tpr_gap(y_true, y_pred, protected_attribute)  # Calculate TPR gap\n",
    "    \n",
    "    soft_final_score = ( soft_macro_f1 + (1 - macro_tpr_gap) ) / 2\n",
    "    return soft_final_score\n",
    "\n",
    "def get_final_score(y_true, y_pred, protected_attribute):\n",
    "    \"\"\"\n",
    "    Combine soft macro F1 score and TPR gap to create a final evaluation metric.\n",
    "    \"\"\"\n",
    "    #convert Tensors to 1 dimension (labels ranging from 0 to 27) if necessary\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1) if y_pred.ndim > 1 else y_pred\n",
    "    y_true_labels = torch.argmax(y_true, dim=1) if y_true.ndim > 1 else y_true\n",
    "\n",
    "    macro_f1 = get_macro_f1(y_true_labels, y_pred_labels)  # Calculate macro F1 score\n",
    "    macro_tpr_gap = get_macro_tpr_gap(y_true_labels, y_pred_labels, protected_attribute)  # Calculate macro TPR gap\n",
    "    \n",
    "    final_score = (macro_f1 + (1 - macro_tpr_gap)) / 2\n",
    "    return final_score\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# TORCH EVALUATION FUNCTIONS\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def evaluate(Y_pred,Y,S,will_print=1):\n",
    "    '''returns model accuracy, final score, macro fscore ans TPR gap\n",
    "    input : 2 np arrays of same dimension\n",
    "    output : array of 4 values\n",
    "    '''\n",
    "    accuracy= accuracy_score(Y, Y_pred)  # Y_test are your original test labels\n",
    "    print(f\"Accuracy on transformed test data: {accuracy}\")\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "    final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "\n",
    "    if will_print==1:\n",
    "        #print results\n",
    "        print('final score',final_score)\n",
    "        print('macro_fscore',eval_scores['macro_fscore'])\n",
    "        print('1-eval_scores[\\'TPR_GAP\\']',1-eval_scores['TPR_GAP'])\n",
    "    \n",
    "    return accuracy, final_score, eval_scores['macro_fscore'],1-eval_scores['TPR_GAP'] , eval_scores , confusion_matrices_eval\n",
    "\n",
    "# to predict X_test and save to file\n",
    "\n",
    "def save_Y_pred_tofile(X, model, name): # adapted to torch\n",
    "    \n",
    "    # save probabilities for each Xi (dim=28)\n",
    "    y_pred_probs = model(X)\n",
    "    probs=pd.DataFrame(y_pred_probs.detach().numpy(), columns= list(range(0,28)))\n",
    "    file_name_probs = \"y_pred_probs/y_pred_probs_\"+str(name)+\".csv\"\n",
    "    probs.to_csv(file_name_probs, header = None, index = None)\n",
    "\n",
    "    # save predicted labels for each Xi (dim=1)\n",
    "    y_pred = torch.argmax(y_pred_probs, dim=1)\n",
    "    results=pd.DataFrame(y_pred.numpy(), columns= ['score'])\n",
    "    file_name = \"y_pred/Data_Challenge_\"+str(name)+\".csv\"\n",
    "    results.to_csv(file_name, header = None, index = None)\n",
    "\n",
    "    return y_pred, y_pred_probs\n",
    "    \n",
    "\n",
    "def print_cassif_report(Y_pred,Y_test):\n",
    "    # Convert Y_pred to a DataFrame\n",
    "    Y_pred_df = pd.DataFrame(Y_pred_tensor.numpy(), columns=['Predicted'])\n",
    "\n",
    "    # Evaluate Y_pred compared to Y_test (assuming Y_test is a numpy array or a pandas Series)\n",
    "    table = classification_report(Y_test, Y_pred_df['Predicted'])\n",
    "\n",
    "    return table\n",
    "\n",
    "#########################################################################\n",
    "#     ENTRAINEMENT DU MODEL (AVEC MINI BATCH / SANS CROSS VALIDATION)\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def train_NN_with_custom_loss(model, optimizer, batch_size, X_train_tensor, Y_train_tensor, S_train_tensor, X_test_tensor, Y_test_tensor, S_test_tensor):\n",
    "\n",
    "    # 1. Convertir les tensors en datasets puis en DataLoader pour gérer les mini-batchs\n",
    "    train_dataset = TensorDataset(X_train_tensor, Y_train_one_hot, S_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_tensor, Y_test_one_hot, S_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "    # 2. Paramètres pour l'arrêt précoce\n",
    "    # -----------------------------------\n",
    "    patience = 5  # Nombre d'époques à attendre après la dernière amélioration de la perte de validation\n",
    "    best_loss = None\n",
    "    early_ending = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # 1/ exécuter les minibatches et recupérer la loss moyenne\n",
    "        for X_batch, Y_batch, S_batch in train_loader:\n",
    "            # Y_batch est one hot\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(X_batch)\n",
    "            loss = soft_final_score_loss(Y_batch, outputs_train, S_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # save mini-batch loss\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Average loss pour l'epoch (après boucle mini-batchs)\n",
    "        train_loss = train_loss / len(train_loader)       \n",
    "        \n",
    "        # 2. Vérifier si la perte de validation s'est améliorée (arret précoce)\n",
    "\n",
    "        # Evaluation sur le jeu de données de test\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch_test, Y_batch_test, S_batch_test in test_loader:\n",
    "                outputs_test = model(X_batch_test)\n",
    "                #Y_batch_test_one_hot = torch.nn.functional.one_hot(Y_batch_test, num_classes=Y_train.nunique())\n",
    "                loss_test = soft_final_score_loss(Y_batch_test, outputs_test, S_batch_test)\n",
    "                test_loss += loss_test.item()\n",
    "                \n",
    "        #average_test_loss = running_loss_test / len(test_loader)\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "       \n",
    "        # check if improvement in loss (compared to last epoch)\n",
    "        if best_loss is None or test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f'Arrêt précoce après {epoch+1} époques')\n",
    "                early_ending = epoch + 1\n",
    "                break  # Arrêter l'entraînement\n",
    "        \n",
    "        # 3. Impression de l'apprentissage et des scores train et test\n",
    "        if epoch==0 or (epoch+1) % 10 == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                # Calculate metrics for training data\n",
    "                outputs_train = model(X_train_tensor) # probabilities\n",
    "                # Evaluate predictions on training data\n",
    "                final_score_train_ = get_final_score(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "                macro_f1_train = get_macro_f1(Y_train_tensor, outputs_train)\n",
    "                inv_macro_tpr_gap_train = 1 - get_macro_tpr_gap(Y_train_tensor, outputs_train, S_train_tensor)\n",
    "            \n",
    "                # Calculate metrics for test data\n",
    "                outputs_test = model(X_test_tensor)\n",
    "                # Evaluate predictions on training data\n",
    "                final_score_test_ = get_final_score(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "                macro_f1_test = get_macro_f1(Y_test_tensor, outputs_test)\n",
    "                inv_macro_tpr_gap_test = 1 - get_macro_tpr_gap(Y_test_tensor, outputs_test, S_test_tensor)\n",
    "\n",
    "                print(f'Epoch {epoch+1}, Loss: {loss.item()}, Final Score Train: {final_score_train_.item()}, Final Score Test: {final_score_test_.item()} (gap {final_score_test_-final_score_train_}) macro F1 Train: {macro_f1_train}, macro F1 Test: {macro_f1_test}, 1-TPR Gap Train: {inv_macro_tpr_gap_train}, 1-TPR Gap Test: {inv_macro_tpr_gap_test}')\n",
    "            \n",
    "    # 4. Make Predictions and Evaluate with final_score\n",
    "    # -------------------------------------------------\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        Y_train_pred_probs = model(X_train_tensor) # dim = 28 (Probabilities for each class)\n",
    "        \n",
    "        # # Y_train_pred_tensor = torch.argmax(Y_train_pred_probs, dim=1)  # dim = 1 (Get the class with the highest probability)\n",
    "        final_score_train = get_final_score(Y_train_tensor, Y_train_pred_probs, S_train_tensor)\n",
    "\n",
    "        Y_pred_probs = model(X_test_tensor) # dim = 28 (Probabilities for each class)\n",
    "        Y_pred_tensor = torch.argmax(Y_pred_probs, dim=1)  # dim = 1 (Get the class with the highest probability)\n",
    "        macro_f1 = get_macro_f1(Y_test_tensor, Y_pred_tensor)\n",
    "        inv_macro_tpr_gap = 1 - get_macro_tpr_gap(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "        final_score = get_final_score(Y_test_tensor, Y_pred_probs, S_test_tensor)\n",
    "        \n",
    "        print(f'Final Evaluation Score: {final_score.item()} gap {final_score.item()-final_score_train.item()} || Macro F1: {macro_f1.item()} 1-TPR_gap: { inv_macro_tpr_gap.item() }')\n",
    "\n",
    "    return model, Y_pred_probs, Y_pred_tensor, final_score, macro_f1, inv_macro_tpr_gap, early_ending,final_score_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (22199, 768) (22199,) (22199,)\n",
      "test: (5550, 768) (5550,) (5550,)\n",
      "train_tensor: torch.Size([22199, 768]) torch.Size([22199]) torch.Size([22199]) <class 'torch.Tensor'>\n",
      "test_tensor: torch.Size([5550, 768]) torch.Size([5550]) torch.Size([5550]) <class 'torch.Tensor'>\n",
      "Y_train_one_hot: torch.Size([22199, 28]) <class 'torch.Tensor'>\n",
      "X_test_true_tensor: torch.Size([11893, 768]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "# train_test_split (np.arrays)\n",
    "##############################################################\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y56_train, Y56_test = train_test_split(debiased_X, Y56, test_size=0.2, random_state=42)\n",
    "\n",
    "Y_train = Y56_train % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_train = Y56_train//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "\n",
    "Y_test = Y56_test % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_test = Y56_test//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "\n",
    "# impression des dimensions\n",
    "print('train:',X_train.shape,Y_train.shape,S_train.shape)\n",
    "print('test:',X_test.shape,Y_test.shape, S_test.shape)\n",
    "\n",
    "##############################################################\n",
    "# 1. Transform DataFrames into Tensors\n",
    "##############################################################\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y.values, dtype=torch.long)\n",
    "S_tensor = torch.tensor(S.values, dtype=torch.long)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "S_train_tensor = torch.tensor(S_train.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.long)\n",
    "S_test_tensor = torch.tensor(S_test.values, dtype=torch.long)\n",
    "\n",
    "Y_train_one_hot = torch.nn.functional.one_hot(Y_train_tensor, num_classes=Y_train.nunique())\n",
    "Y_test_one_hot = torch.nn.functional.one_hot(Y_test_tensor, num_classes=Y_train.nunique())\n",
    "\n",
    "X_test_true_tensor = torch.tensor(X_test_true.values, dtype=torch.float32)\n",
    "#S_test_true_tensor = torch.tensor(S_test_true.values, dtype=torch.long)\n",
    "\n",
    "# impression des dimensions\n",
    "print('train_tensor:',X_train_tensor.shape,Y_train_tensor.shape,S_train_tensor.shape, type(X_train_tensor))\n",
    "print('test_tensor:',X_test_tensor.shape,Y_test_tensor.shape, S_test_tensor.shape, type(X_test_tensor))\n",
    "print('Y_train_one_hot:',Y_train_one_hot.shape, type(Y_train_one_hot))\n",
    "print('X_test_true_tensor:',X_test_true_tensor.shape, type(X_test_true_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Starting to train model NN-28-28_Adam_lr_0.001_batch_size_512\n",
      "Epoch 1, Loss: 0.9312233328819275, Final Score Train: 0.5614883899688721, Final Score Test: 0.561823844909668 (gap 0.00033545494079589844) macro F1 Train: 0.13548072378038073, macro F1 Test: 0.13768619321322936, 1-TPR Gap Train: 0.987496018409729, 1-TPR Gap Test: 0.9859615564346313\n",
      "Epoch 10, Loss: 0.6553373336791992, Final Score Train: 0.7950546741485596, Final Score Test: 0.7695534229278564 (gap -0.025501251220703125) macro F1 Train: 0.6346785599846217, macro F1 Test: 0.5994005510131909, 1-TPR Gap Train: 0.9554307460784912, 1-TPR Gap Test: 0.9397063255310059\n",
      "Epoch 20, Loss: 0.650231122970581, Final Score Train: 0.8250597715377808, Final Score Test: 0.776787519454956 (gap -0.04827225208282471) macro F1 Train: 0.6913052690432434, macro F1 Test: 0.6227293060857644, 1-TPR Gap Train: 0.9588142037391663, 1-TPR Gap Test: 0.9308457374572754\n",
      "Epoch 30, Loss: 0.696786105632782, Final Score Train: 0.8408527374267578, Final Score Test: 0.7836859226226807 (gap -0.05716681480407715) macro F1 Train: 0.7236424256061262, macro F1 Test: 0.634391349999249, 1-TPR Gap Train: 0.958063006401062, 1-TPR Gap Test: 0.9329805374145508\n",
      "Arrêt précoce après 37 époques\n",
      "Final Evaluation Score: 0.7836616039276123 gap -0.06377959251403809 || Macro F1: 0.6381215602576634 1-TPR_gap: 0.929201602935791\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#       TEST D'UN MODEL (ET DU CODE)\n",
    "################################################\n",
    "\n",
    "\n",
    "# 1. Define the model and optimizer and train\n",
    "# --------------------------------------------------\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(768, 28),  # Assuming 768 input features and 28 classes\n",
    "    nn.ReLU(),  # Adding a ReLU activation function\n",
    "    nn.Linear(28, 28),\n",
    "    nn.Softmax(dim=1),  # LogSoftmax for multi-class classification\n",
    "    )  \n",
    "\n",
    "batch_size = 512\n",
    "learning_rate=0.001\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=1/0.2)\n",
    "num_epochs = 1000\n",
    "\n",
    "# 2. Train the model with the custom loss function final_eval\n",
    "# -----------------------------------------------------------\n",
    "name = 'NN-28-28_Adam'+'_lr_'+str(learning_rate)+'_batch_size_'+str(batch_size)\n",
    "print('\\n\\n Starting to train model', name)\n",
    "model_trained, Y_pred_probs, Y_pred_tensor, final_score, macro_f1, inv_macro_tpr_gap, early_ending, final_score_train = train_NN_with_custom_loss(model,optim.Adam(model.parameters(), lr=learning_rate), batch_size, X_train_tensor, Y_train_tensor, S_train_tensor, X_test_tensor, Y_test_tensor, S_test_tensor)\n",
    "\n",
    "# Res=pd.DataFrame(columns=['model','optimizer','lr','batch_size','early_ending', 'final_score_train','final_score','macro_f1','macro_tpr_gap'])\n",
    "# Res.loc[i]=[name,optimizer,learning_rate,batch_size, early_ending,final_score_train, final_score, macro_f1, inv_macro_tpr_gap]\n",
    "\n",
    "# Save predictions on X_test_true\n",
    "save_Y_pred_tofile(X_test_true_tensor, model_trained,name)\n",
    "\n",
    "# save model\n",
    "with open(path_model + name + '.pkl', 'wb') as f: pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"SENSITIVE FRONTIER\" MODELS <br>(USED ON DEBIASED DATASET)**\n",
    "---\n",
    "K nearest neighboors<br>\n",
    "SVM linear<br>\n",
    "SVM gaussian kernel<br>\n",
    "One versus all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LINEAR REGRESSION OF MODELS**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [ '0_LogReg_baseline' , \n",
    "        '1_LogReg_optimised' , \n",
    "        '2_Reglog_StratKFold',\n",
    "        '3_LogReg_optimised_orthogonal 78,08%' , \n",
    "        '4_Reglog_DUAL_orthogonal_FxH',\n",
    "        '4_Reglog_DUAL_orthogonal_F',\n",
    "        '4_Reglog_DUAL_orthogonal_H',\n",
    "        '5_Reglog56_StratKFold_Orthogonal_CustomLoss',\n",
    "        '6_NN-28-28_Adam_lr_0.001_batch_size_512'\n",
    "        ]\n",
    "\n",
    "with open(path_model + list[0] + '.pkl', 'rb') as f: clf_0 = pickle.load(f)\n",
    "with open(path_model + list[1] + '.pkl', 'rb') as f: clf_1 = pickle.load(f)\n",
    "with open(path_model + list[2] + '.pkl', 'rb') as f: clf_2 = pickle.load(f)\n",
    "with open(path_model + list[3] + '.pkl', 'rb') as f: clf_3 = pickle.load(f)\n",
    "with open(path_model + list[4] + '.pkl', 'rb') as f: clf_4 = pickle.load(f)\n",
    "with open(path_model + list[5] + '.pkl', 'rb') as f: clf_4F = pickle.load(f)\n",
    "with open(path_model + list[6] + '.pkl', 'rb') as f: clf_4H = pickle.load(f)\n",
    "with open(path_model + list[7] + '.pkl', 'rb') as f: clf_5 = pickle.load(f)\n",
    "with open(path_model + list[8] + '.pkl', 'rb') as f: clf_6 = pickle.load(f)\n",
    "# with open(path_model + list[7] + '.pkl', 'rb') as f: clf_7 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.2, max_iter=5000, random_state=42, verbose=1) (27749,)\n",
      "LogisticRegression(C=0.2, max_iter=5000, random_state=42) (27749,)\n",
      "(27749, 6)\n",
      "Accuracy on transformed test data: 0.8590940214061767\n",
      "final score : 0.870375472870099\n",
      "macro_f1    : 0.8345467456152175\n",
      "inv_macro_gap 0.9062042001249804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  6.,  6.,  6.,  0.,  6.],\n",
       "       [ 9.,  9.,  9.,  9.,  1.,  9.],\n",
       "       [ 6.,  6.,  6.,  6.,  0.,  6.],\n",
       "       [22., 22., 22., 22.,  1., 22.],\n",
       "       [21., 21., 21., 21.,  0., 21.],\n",
       "       [25., 19., 19., 25.,  1., 19.],\n",
       "       [18., 18., 18., 18.,  0., 18.],\n",
       "       [13., 13., 13., 13.,  1., 13.],\n",
       "       [18., 18., 18., 18.,  1., 18.],\n",
       "       [19., 19., 19., 19.,  0., 19.],\n",
       "       [ 6.,  6.,  6.,  6.,  1.,  6.],\n",
       "       [ 2.,  2.,  2.,  2.,  0.,  2.],\n",
       "       [21., 21., 21., 21.,  0., 21.],\n",
       "       [ 9.,  9.,  9., 21.,  0.,  9.],\n",
       "       [21., 21., 21., 21.,  0., 21.],\n",
       "       [ 1.,  1.,  1.,  1.,  0.,  1.],\n",
       "       [26.,  1., 26., 26.,  1., 26.],\n",
       "       [26., 26., 26., 26.,  1., 12.],\n",
       "       [26., 21., 26., 26.,  1., 26.],\n",
       "       [19., 25., 25., 19.,  0., 11.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dataframe will all predictions for X\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for clf in [ clf_3,clf_5] : # clf1 and 2 are identical\n",
    "    \n",
    "    preds = clf.predict(debiased_X)\n",
    "    print( clf,preds.shape)\n",
    "    predictions.append(preds)\n",
    "\n",
    "# Ajout mannuel du prédicteur dual (clf_4)\n",
    "# Predict model on test_true\n",
    "Y_pred_F = model_F.predict(debiased_X_F)\n",
    "Y_pred_H = model_H.predict(debiased_X_H)\n",
    "# compute final result depending on S_test_true\n",
    "Y_pred_4 = np.zeros(len(X))\n",
    "Y_pred_4[ S == 1 ] = Y_pred_F\n",
    "Y_pred_4[ S == 0 ] = Y_pred_H\n",
    "predictions.append(Y_pred_4)\n",
    "\n",
    "\n",
    "\n",
    "#Ajout du NN\n",
    "output_6_NN = model_trained(X_tensor)\n",
    "output_6_labels = torch.argmax(output_6_NN, dim=1)\n",
    "predictions.append(output_6_labels)\n",
    "\n",
    "# Ajout de Y et S pour analyse\n",
    "predictions.append(S)\n",
    "predictions.append(Y)\n",
    "\n",
    "X_predictions = np.column_stack(predictions)\n",
    "X_predictions[:, 1] = X_predictions[:, 1] % 28  # corriger Y56\n",
    "\n",
    "print(X_predictions.shape)\n",
    "X_predictions[:20,:]\n",
    "\n",
    "#-----------------------------------\n",
    "#   prediction\n",
    "#-----------------------------------\n",
    "\n",
    "from scipy.stats import mode\n",
    "# Trouver le mode dans chaque ligne\n",
    "modes, counts = mode(X_predictions[:,:-2], axis=1)  # ne pas prendre les 2 dernières colonnes Y et S\n",
    "\n",
    "# Le mode est retourné dans un array; nous le simplifions pour un usage direct\n",
    "Y_pred = modes.flatten()\n",
    "\n",
    "get_scores(Y_pred,Y,S)\n",
    "# modes_simplified.to_csv(path_Y_pred_true + \"Data_Challenge_GLOBAL.csv\", header = None, index = None)\n",
    "X_predictions[:20,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.2, max_iter=5000, random_state=42, verbose=1) (11893,)\n",
      "LogisticRegression(C=0.2, max_iter=5000, random_state=42) (11893,)\n",
      "(11893, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18., 18., 18., 18.,  0.],\n",
       "       [21., 21., 21., 21.,  0.],\n",
       "       [18., 12., 18., 18.,  0.],\n",
       "       [ 2.,  2.,  2.,  2.,  0.],\n",
       "       [21., 21., 13., 21.,  1.],\n",
       "       [ 4.,  4.,  4.,  4.,  0.],\n",
       "       [18., 13., 13., 12.,  1.],\n",
       "       [18., 18., 18., 18.,  0.],\n",
       "       [18., 11., 18., 18.,  0.],\n",
       "       [19., 19., 19., 19.,  1.],\n",
       "       [13., 13., 13., 13.,  0.],\n",
       "       [26.,  5.,  5., 24.,  0.],\n",
       "       [21., 21., 21., 21.,  0.],\n",
       "       [19., 19., 19., 19.,  0.],\n",
       "       [11., 11., 11., 11.,  1.],\n",
       "       [21., 21., 21., 21.,  0.],\n",
       "       [11., 11., 11., 11.,  1.],\n",
       "       [21., 21., 21., 21.,  1.],\n",
       "       [21., 21., 21., 21.,  0.],\n",
       "       [18., 18., 18., 18.,  0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dataframe will all predictions for X_test_true\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for clf in [ clf_3,clf_5] :  # clf1 and 2 are identical\n",
    "    \n",
    "    preds = clf.predict(debiased_X_test_true)\n",
    "    print( clf,preds.shape)\n",
    "    predictions.append(preds)\n",
    "\n",
    "# Ajout mannuel du prédicteur dual (clf_4)\n",
    "# Predict model on test_true\n",
    "Y_pred_F = model_F.predict(debiased_X_test_true_F)\n",
    "Y_pred_H = model_H.predict(debiased_X_test_true_H)\n",
    "# compute final result depending on S_test_true\n",
    "Y_pred_4 = np.zeros(len(X_test_true))\n",
    "Y_pred_4[ S_test_true == 1 ] = Y_pred_F\n",
    "Y_pred_4[ S_test_true == 0 ] = Y_pred_H\n",
    "predictions.append(Y_pred_4)\n",
    "\n",
    "#Ajout du NN\n",
    "output_6_NN = model_trained(X_test_true_tensor)\n",
    "output_6_labels = torch.argmax(output_6_NN, dim=1)\n",
    "predictions.append(output_6_labels)\n",
    "\n",
    "# Ajout de S #+1 si femme et - 1 si homme (S - 0.5)*2\n",
    "predictions.append(S_test_true)\n",
    "\n",
    "# Ajout de Y pour comparer\n",
    "#predictions.append(Y)\n",
    "\n",
    "# Ajuster les valeurs pour la rgression sur Y56\n",
    "X_predictions = np.column_stack(predictions)\n",
    "X_predictions[:, 1] = X_predictions[:, 1] % 28\n",
    "\n",
    "print(X_predictions.shape)\n",
    "X_predictions[:20,:]\n",
    "\n",
    "#-----------------------------------\n",
    "#   prediction\n",
    "#-----------------------------------\n",
    "\n",
    "from scipy.stats import mode\n",
    "# Trouver le mode dans chaque ligne\n",
    "modes, counts = mode(X_predictions[:,:-1], axis=1)\n",
    "\n",
    "# Le mode est retourné dans un array; nous le simplifions pour un usage direct\n",
    "Y_true_pred = modes.flatten().astype(int)\n",
    "Y_true_pred = pd.DataFrame(Y_true_pred)\n",
    "Y_true_pred.to_csv(path_Y_pred_true + \"Data_Challenge_GLOBAL.csv\", header = None, index = None)\n",
    "\n",
    "X_predictions[:20,:]\n",
    "#X_predictions[:20,:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCORES A BLANC**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#   SCORE A BLANC\n",
    "#####################################################\n",
    "\n",
    "\n",
    "n=Y.shape[0]\n",
    "Y_pred =np.ones(n)*1\n",
    "accuracy= accuracy_score(Y, Y_pred)  # Y_test are your original test labels\n",
    "print(f\"Accuracy on transformed test data: {accuracy}\")\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "\n",
    "#print results\n",
    "print('final score',final_score)\n",
    "print('macro_fscore',eval_scores['macro_fscore'])\n",
    "print('1-eval_scores[\\'TPR_GAP\\']',1-eval_scores['TPR_GAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score \"prediction uniforme\"\n",
    "\n",
    "n=Y.shape[0]\n",
    "\n",
    "Scores_U=pd.DataFrame(columns=['N','N_f','N_h','accuracy','final_score','macro_f1','macro_gap'])\n",
    "\n",
    "print(Scores_U)\n",
    "for i in range(28):\n",
    "    #Test value for all i values\n",
    "    test=pd.DataFrame(np.ones(11893,dtype=int)*i)\n",
    "    test.to_csv(\"all/Data_Challenge_all_\"+str(i)+\".csv\", header = None, index = None)\n",
    "    \n",
    "    Y_pred=pd.DataFrame(np.ones(n,dtype=int)*i)\n",
    "    accuracy= accuracy_score(Y, Y_pred)  # Y_test are your original test labels\n",
    "    eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred, Y, S, metrics=['TPR'])\n",
    "    macro_f1 = eval_scores['macro_fscore']\n",
    "    macro_gap = eval_scores['TPR_GAP']\n",
    "    final_score = (macro_f1 +1- macro_gap)/2\n",
    "    # check number of occurence\n",
    "    N = (Y==i).sum()\n",
    "    N_f = (Y56 == i + 28).sum()\n",
    "    N_h = (Y56 == i).sum()\n",
    "    Scores_U.loc[i]= [N, N_f, N_h, accuracy,final_score,macro_f1,macro_gap]\n",
    "\n",
    "Scores_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = Scores_U['N']\n",
    "score = Scores_U['final_score']\n",
    "\n",
    "\n",
    "# Créer et entraîner le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reverse = LinearRegression()\n",
    "reverse.fit(np.array(score).reshape(-1, 1),np.array(size).reshape(-1, 1))\n",
    "\n",
    "# Load the scores for X_true\n",
    "scores_true = pd. read_csv('all/distribution_Y_true.txt',header = None,index_col=0)\n",
    "dist_true_pred = reverse.predict(scores_true) #/ 11893 * 27749\n",
    "\n",
    "# Afficher la distribution de X_test_true\n",
    "plt.scatter(size,score)\n",
    "plt.scatter(dist_true_pred,scores_true)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Scores_U['final_score'],scores_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(28),size,label='X')\n",
    "plt.plot(range(28),np.round(dist_true_pred),'X_test_true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data (L2 norm recommended for embeddings)\n",
    "#X = normalize(X, norm='l2')\n",
    "#X_test_true = normalize(X_test_true, norm='l2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# train_test_split with Y56 (np.arrays)\n",
    "##############################################################\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y56_train, Y56_test = train_test_split(X, Y56, test_size=0.2, random_state=42)\n",
    "Y_train = Y56_train % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_train = Y56_train//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "Y_test = Y56_test % 28  # reste (original Y)   ex 33% 28 = classe 5 \n",
    "S_test = Y56_test//28   # facteur (original S) ex 33//28 = 1 (attribut protégé)\n",
    "\n",
    "# impression des dimensions\n",
    "print('train:',X_train.shape,Y_train.shape,S_train.shape)\n",
    "print('test:',X_test.shape,Y_test.shape, S_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.DataFrame({'label':Y,'S':S})\n",
    "\n",
    "# Sum counts of 1s and 0s to get the total count for each label\n",
    "result = dist.groupby('label')['S'].value_counts().unstack(fill_value=0)\n",
    "result.columns = ['S', 'not_S']\n",
    "result['total_count'] = result.sum(axis=1)\n",
    "\n",
    "# Calculate totals for each column\n",
    "totals = result.sum(axis=0)\n",
    "result.loc[30] = totals\n",
    "\n",
    "# Calculate total count percentages for each count\n",
    "result['%_S_label'] = round((result['S'] / result['total_count']) * 100)\n",
    "result['%_not_S_label'] = round((result['not_S'] / result['total_count']) * 100)\n",
    "result['%_total'] = np.round(result['total_count']/len(Y)*100,2 ) # % of total count\n",
    "result['%_S_total'] = np.round(result['S']/(S==1).sum()*100,2 ) # % of total count\n",
    "result['%_not_S_total'] = np.round(result['not_S']/(S!=1).sum()*100,2 ) # % of total count\n",
    "result['diff_%_S_total']=result['%_S_total']-result['%_total']\n",
    "result['|']='|'\n",
    "#Reorder table\n",
    "result = result.reindex(columns=['total_count', '%_total','|','S','%_S_total','diff_%_S_total','|','not_S', '%_not_S_total','|','%_S_label', '%_not_S_label'])\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the '%_S' column\n",
    "labels = pd.to_numeric(result.index)\n",
    "data = result['%_total']\n",
    "data_S = result['%_S_total']\n",
    "data_not_S = result['%_not_S_total']\n",
    "\n",
    "# Create a bar plot\n",
    "plt.plot(labels[:-1], data[:-1])\n",
    "plt.plot(labels[:-1],data_S[:-1], label='Sensitive')\n",
    "plt.plot(labels[:-1],data_not_S[:-1], label='Not_sensitive')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Percentage of total')\n",
    "plt.title('Percentage of total for sample, S and non-S')\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sorted = result.iloc[:-1].sort_values(by='diff_%_S_total', ascending=False)\n",
    "result_sorted['original_label'] = result_sorted.index\n",
    "result_sorted=result_sorted.reset_index(drop=True)\n",
    "#result_sorted.reset_index(drop=True, inplace=True)\n",
    "result_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the '%_S' column\n",
    "labels_sorted = result_sorted['original_label']\n",
    "#print(labels_sorted)\n",
    "data = result_sorted['%_total']\n",
    "data_S = result_sorted['%_S_total']\n",
    "data_not_S = result_sorted['%_not_S_total']\n",
    "\n",
    "# Create a bar plot\n",
    "plt.plot(data)\n",
    "plt.plot(data_S, label='Sensitive')\n",
    "plt.plot(data_not_S, label='Not_sensitive')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Percentage of total')\n",
    "#plt.xticks(labels_sorted)\n",
    "plt.xticks(ticks=range(len(labels_sorted)), labels=labels_sorted, rotation=90)  # Rotate if there are many labels\n",
    "\n",
    "plt.title('Percentage of total for sample, S and non-S')\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECOND METHOD - ADVERSARIAL NN**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh training data\n",
    "# X_train, X_test, Y_train, Y_test, S_train, S_test = X_train_, X_test_, Y_train_, Y_test_, S_train_, S_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22199, 768) (22199, 28) (22199,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5019 - loss: -32135.4043 - main_task_output_accuracy: 0.3827\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -1229957.5000 - main_task_output_accuracy: 0.1678\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -6222336.0000 - main_task_output_accuracy: 0.1413\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -16569529.0000 - main_task_output_accuracy: 0.1412\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -33675884.0000 - main_task_output_accuracy: 0.1342\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -57282136.0000 - main_task_output_accuracy: 0.1351\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -88983400.0000 - main_task_output_accuracy: 0.1304\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -126994416.0000 - main_task_output_accuracy: 0.1394\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -174621376.0000 - main_task_output_accuracy: 0.1316\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_3: 0.5000 - loss: -232675264.0000 - main_task_output_accuracy: 0.1369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3d79bf60b0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy , CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming X_train is your input embeddings and S is your sensitive attribute\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(768,))\n",
    "\n",
    "# Main task classifier layers\n",
    "main_task_hidden = Dense(256, activation='relu')(input_layer)\n",
    "main_task_output = Dropout(0.5)(main_task_hidden)\n",
    "main_task_output = Dense(28, activation='softmax', name='main_task_output')(main_task_hidden)\n",
    "\n",
    "# Adversarial component layers\n",
    "adversary_hidden = Dense(256, activation='relu')(main_task_hidden)\n",
    "adversary_hidden = Dropout(0.5)(adversary_hidden)\n",
    "adversarial_output = Dense(1, activation='sigmoid', name='adversarial_output')(adversary_hidden)\n",
    "\n",
    "# Model\n",
    "model_2 = Model(inputs=input_layer, outputs=[main_task_output, adversarial_output])\n",
    "\n",
    "# Optimizers\n",
    "#main_task_optimizer = Adam(learning_rate=0.001)\n",
    "#adversarial_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Loss functions\n",
    "main_task_loss = CategoricalCrossentropy()\n",
    "adversarial_loss = BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'main_task_output': main_task_loss, 'adversarial_output': adversarial_loss},\n",
    "              loss_weights={'main_task_output':1., 'adversarial_output':-0.1},\n",
    "              metrics={'main_task_output': ['accuracy'], 'adversarial_output': [AUC()]})\n",
    "\n",
    "# Prepare the labels for the main task and the adversarial task\n",
    "Y_main_task = to_categorical(Y_train, num_classes=28)#Y_train # Your main task labels\n",
    "Y_adversary = S_train    # Your sensitive attribute labels\n",
    "\n",
    "# check size on input .output\n",
    "print(X_train.shape,Y_main_task.shape,Y_adversary.shape)\n",
    "\n",
    "# X normal:isation\n",
    "# none in method 2\n",
    "\n",
    "# Train the model\n",
    "model_2.fit(X_train, {'main_task_output': Y_main_task, 'adversarial_output': Y_adversary}, epochs=10)\n",
    "\n",
    "# After training, you can use the output of `main_task_hidden` as your new unbiased representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 2: Train a new classifier on the transformed training data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m clf_2 \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)  \u001b[38;5;66;03m# Increase max_iter if needed for convergence\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m history_new_2 \u001b[38;5;241m=\u001b[39m \u001b[43mclf_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Y_train are your original training labels\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 3: Predict on the transformed test data and evaluate\u001b[39;00m\n\u001b[1;32m     12\u001b[0m Y_pred_2 \u001b[38;5;241m=\u001b[39m clf_2\u001b[38;5;241m.\u001b[39mpredict(X_test_transformed_2)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1296\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[1;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    454\u001b[0m ]\n\u001b[0;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    470\u001b[0m     solver,\n\u001b[1;32m    471\u001b[0m     opt_res,\n\u001b[1;32m    472\u001b[0m     max_iter,\n\u001b[1;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:369\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    363\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_optimize.py:78\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/scipy/optimize/_optimize.py:72\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 72\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/sklearn/linear_model/_linear_loss.py:302\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    300\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 302\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    304\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Transform X_train and X_test\n",
    "feature_extractor_2 = Model(inputs=model_2.input, outputs=main_task_hidden)\n",
    "X_train_transformed_2 = feature_extractor_2.predict(X_train)\n",
    "X_test_transformed_2 = feature_extractor_2.predict(X_test)\n",
    "X_test_true_transformed_2 = feature_extractor_2.predict(X_test_true)\n",
    "\n",
    "# Step 2: Train a new classifier on the transformed training data\n",
    "clf_2 = LogisticRegression(random_state=42, max_iter=5000,verbose=0,penalty='l2', C=0.2, tol=0.0001)  # Increase max_iter if needed for convergence\n",
    "history_new_2 = clf_2.fit(X_train_transformed_2, Y_train)  # Y_train are your original training labels\n",
    "\n",
    "# Step 3: Predict on the transformed test data and evaluate\n",
    "Y_pred_2 = clf_2.predict(X_test_transformed_2)\n",
    "accuracy_2= accuracy_score(Y_test, Y_pred_2)  # Y_test are your original test labels\n",
    "print(f\"Accuracy on transformed test data: {accuracy_2}\")\n",
    "\n",
    "# Step 4 : Predict with gloabl score\n",
    "eval_scores_2, confusion_matrices_eval_2 = gap_eval_scores(Y_pred_2, Y_test, S_test, metrics=['TPR'])\n",
    "final_score_2 = (eval_scores_2['macro_fscore']+ (1-eval_scores_2['TPR_GAP']))/2\n",
    "print('\\nfinal',final_score_2)\n",
    "print('macro_fscore',eval_scores_2['macro_fscore'])\n",
    "print('1-eval_scores',1-eval_scores_2['TPR_GAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the provided test data with you classifier\n",
    "y_test = clf_2.predict(X_test_true_transformed_2)\n",
    "results=pd.DataFrame(y_test, columns= ['score'])\n",
    "\n",
    "results.to_csv(\"Data_Challenge_Adversarial_NN.csv\", header = None, index = None)\n",
    "# np.savetxt('y_test_challenge_student.txt', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THIRD METHOD**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# get X_train an\n",
    "# X_train, X_test, Y_train, Y_test, S_train, S_test = train_test_split(X, Y, S, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform your training data\n",
    "X_train_standardized = scaler.transform(X_train)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "X_test_true_standardized = scaler.transform(X_test_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22199, 768) (22199, 28) (22199,)\n",
      "Epoch 1/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.5372 - loss: 2.4315 - main_task_output_accuracy: 0.5348\n",
      "Epoch 2/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.7183 - loss: 1.5883 - main_task_output_accuracy: 0.7021\n",
      "Epoch 3/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.8276 - loss: 1.4163 - main_task_output_accuracy: 0.7226\n",
      "Epoch 4/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.8988 - loss: 1.2303 - main_task_output_accuracy: 0.7462\n",
      "Epoch 5/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.9271 - loss: 1.1553 - main_task_output_accuracy: 0.7520\n",
      "Epoch 6/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.9512 - loss: 1.0795 - main_task_output_accuracy: 0.7511\n",
      "Epoch 7/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.9569 - loss: 1.0326 - main_task_output_accuracy: 0.7607\n",
      "Epoch 8/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.9656 - loss: 0.9945 - main_task_output_accuracy: 0.7597\n",
      "Epoch 9/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - adversarial_output_auc_5: 0.9710 - loss: 0.9580 - main_task_output_accuracy: 0.7636\n",
      "Epoch 10/10\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - adversarial_output_auc_5: 0.9752 - loss: 0.9223 - main_task_output_accuracy: 0.7686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3cd80e6560>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy , CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming X_train is your input embeddings and S is your sensitive attribute\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(768,))\n",
    "\n",
    "# Main task classifier layers\n",
    "main_task_hidden = Dense(256, activation='relu')(input_layer)\n",
    "main_task_hidden = Dropout(0.5)(main_task_hidden)\n",
    "main_task_output = Dense(28, activation='softmax', name='main_task_output')(main_task_hidden)\n",
    "\n",
    "# Adversarial component layers\n",
    "adversary_hidden = Dense(256, activation='relu')(main_task_hidden)\n",
    "adversary_hidden = Dropout(0.5)(adversary_hidden)\n",
    "adversarial_output = Dense(1, activation='sigmoid', name='adversarial_output')(adversary_hidden)\n",
    "\n",
    "# Model\n",
    "model_3 = Model(inputs=input_layer, outputs=[main_task_output, adversarial_output])\n",
    "\n",
    "# Optimizers\n",
    "#main_task_optimizer = Adam(learning_rate=0.001)\n",
    "#adversarial_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Loss functions\n",
    "main_task_loss = CategoricalCrossentropy()\n",
    "adversarial_loss = BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'main_task_output': main_task_loss, 'adversarial_output': adversarial_loss},\n",
    "              metrics={'main_task_output': ['accuracy'], 'adversarial_output': [AUC()]})\n",
    "\n",
    "# Prepare the labels for the main task and the adversarial task\n",
    "Y_main_task = to_categorical(Y_train, num_classes=28)#Y_train # Your main task labels\n",
    "Y_adversary = S_train    # Your sensitive attribute labels\n",
    "\n",
    "# check size on input .output\n",
    "print(X_train.shape,Y_main_task.shape,Y_adversary.shape)\n",
    "\n",
    "# Train the model\n",
    "model_3.fit(X_train, {'main_task_output': Y_main_task, 'adversarial_output': Y_adversary}, epochs=10)\n",
    "\n",
    "# After training, you can use the output of `main_task_hidden` as your new unbiased representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/694\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 25ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step\n",
      "Accuracy on transformed test data: 0.7727927927927928\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Transform X_train and X_test\n",
    "feature_extractor_3 = Model(inputs=model_3.input, outputs=main_task_hidden)\n",
    "X_train_transformed_3 = feature_extractor_3.predict(X_train)\n",
    "X_test_transformed_3 = feature_extractor_3.predict(X_test)\n",
    "X_test_true_transformed_3 = feature_extractor_3.predict(X_test_true)\n",
    "\n",
    "# Step 2: Train a new classifier on the transformed training data\n",
    "new_classifier_3 = LogisticRegression(max_iter=10000)  # Increase max_iter if needed for convergence\n",
    "history_new_3 = new_classifier_3.fit(X_train_transformed_3, Y_train)  # Y_train are your original training labels\n",
    "\n",
    "# Step 3: Predict on the transformed test data and evaluate\n",
    "Y_pred_3 = new_classifier_3.predict(X_test_transformed_3)\n",
    "accuracy_3= accuracy_score(Y_test, Y_pred_3)  # Y_test are your original test labels\n",
    "print(f\"Accuracy on transformed test data: {accuracy_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_fscore 0.6712117457725401\n",
      "1-eval_scores 0.7484002113701219\n",
      "final score (average) 0.709805978571331\n"
     ]
    }
   ],
   "source": [
    "# calculate final score\n",
    "eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred_3, Y_test, S_test, metrics=['TPR'])\n",
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "\n",
    "print('macro_fscore',eval_scores['macro_fscore'])\n",
    "print('1-eval_scores',1-eval_scores['TPR_GAP'])\n",
    "print('final score (average)',final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/372\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the \"true\" test data\n",
    "X_test_true = dat['X_test']\n",
    "S_test_true = dat['S_test'] \n",
    "\n",
    "X_test_true_transformed_3 = feature_extractor_3.predict(X_test_true)\n",
    "\n",
    "# Classify the provided test data with you classifier\n",
    "y_test_true = new_classifier_3.predict(X_test_true_transformed_3)\n",
    "results_3=pd.DataFrame(y_test_true, columns= ['score'])\n",
    "\n",
    "results_3.to_csv(\"Data_Challenge_AdversarialNN_2.csv\", header = None, index = None)\n",
    "# np.savetxt('y_test_challenge_student.txt', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4th METHOD**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy , CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming X_train is your input embeddings and S is your sensitive attribute\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(768,))\n",
    "\n",
    "# Main task classifier layers\n",
    "main_task_hidden = Dense(512, activation='relu')(input_layer)\n",
    "main_task_hidden = Dropout(0.5)(main_task_hidden)\n",
    "main_task_output = Dense(28, activation='softmax', name='main_task_output')(main_task_hidden)\n",
    "\n",
    "# Adversarial component layers\n",
    "adversary_hidden = Dense(512, activation='relu')(main_task_hidden)\n",
    "adversary_hidden = Dropout(0.5)(adversary_hidden)\n",
    "adversarial_output = Dense(1, activation='sigmoid', name='adversarial_output')(adversary_hidden)\n",
    "\n",
    "# Model\n",
    "model_4 = Model(inputs=input_layer, outputs=[main_task_output, adversarial_output])\n",
    "\n",
    "# Optimizers\n",
    "#main_task_optimizer = Adam(learning_rate=0.001)\n",
    "#adversarial_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Loss functions\n",
    "main_task_loss = CategoricalCrossentropy()\n",
    "adversarial_loss = BinaryCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model_4.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'main_task_output': main_task_loss, 'adversarial_output': adversarial_loss},\n",
    "              metrics={'main_task_output': ['accuracy'], 'adversarial_output': [AUC()]})\n",
    "\n",
    "# Prepare the labels for the main task and the adversarial task\n",
    "Y_main_task = to_categorical(Y_train, num_classes=28)#Y_train # Your main task labels\n",
    "Y_adversary = S_train    # Your sensitive attribute labels\n",
    "\n",
    "# check size on input .output\n",
    "print(X_train_standardized.shape,Y_main_task.shape,Y_adversary.shape)\n",
    "\n",
    "# Train the model\n",
    "model_4.fit(X_train_standardized, {'main_task_output': Y_main_task, 'adversarial_output': Y_adversary}, epochs=10)\n",
    "\n",
    "# After training, you can use the output of `main_task_hidden` as your new unbiased representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Transform X_train and X_test\n",
    "feature_extractor_4 = Model(inputs=model_4.input, outputs=main_task_hidden)\n",
    "X_train_transformed_4 = feature_extractor_4.predict(X_train_standardized)\n",
    "X_test_transformed_4 = feature_extractor_4.predict(X_test_standardized)\n",
    "X_test_true_transformed_4 = feature_extractor_4.predict(X_test_true_standardized)\n",
    "\n",
    "# Step 2: Train a new classifier on the transformed training data\n",
    "new_classifier_4 = LogisticRegression(max_iter=10000)  # Increase max_iter if needed for convergence\n",
    "history_4 = new_classifier_4.fit(X_train_transformed_4, Y_train)  # Y_train are your original training labels\n",
    "\n",
    "# Step 3: Predict on the transformed test data and evaluate\n",
    "Y_pred_4 = new_classifier_4.predict(X_test_transformed_4)\n",
    "accuracy_4 = accuracy_score(Y_test, Y_pred_4)  # Y_test are your original test labels\n",
    "print(f\"Accuracy on transformed test data: {accuracy_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores, confusion_matrices_eval = gap_eval_scores(Y_pred_4, Y_test, S_test, metrics=['TPR'])\n",
    "#eval_scores#eval_scores['macro_fscore']\n",
    "#eval_scores['TPR_GAP']\n",
    "final_score = (eval_scores['macro_fscore']+ (1-eval_scores['TPR_GAP']))/2\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"true\" test data\n",
    "X_test_true = dat['X_test']\n",
    "S_test_true = dat['S_test'] \n",
    "\n",
    "X_test_true_transformed_4 = feature_extractor_4.predict(X_test_true)\n",
    "\n",
    "# Classify the provided test data with you classifier\n",
    "y_test_true = clf.predict(X_test_true_transformed_4)\n",
    "results_4=pd.DataFrame(y_test_true, columns= ['score'])\n",
    "\n",
    "results_4.to_csv(\"Data_Challenge_MDI_341_4.csv\", header = None, index = None)\n",
    "# np.savetxt('y_test_challenge_student.txt', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python WSL (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
